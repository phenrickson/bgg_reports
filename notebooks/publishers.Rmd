---
title: "Examining BGG Publishers"
author: Phil Henrickson
params:
        train_year: 2020
        min_ratings: 50
---

```{r setup, inclue=F, results = 'hide', message=F, warning=F}

source(here::here("src", "helpers", "exploratory_setup.R"))

```

```{r load functions for categorical, include=F} 

source(here::here("src", "functions", "explore_categorical_functions.R"))

```


```{r create tidy games, include=F}

# set minimum ratings
min_ratings = params$min_ratings

# train year
train_year = params$train_year

# remove unreleased and problem games
tidy_games =
        analysis_games %>%
        # remove unreleased and problem games
        filter(!(game_id %in% c(
                unreleased_games$game_id,
                drop_games$game_id))
        ) %>%
        # filter out games with missingness on yearpublished
        filter(!is.na(yearpublished)) %>%
        # filter out games with missingness on average weight
        filter(!is.na(averageweight) & averageweight!=0) %>%
        # filter our kickstarter editions and big box editions
        filter(!(grepl("kickstarter|big box|mega box|megabox", name))) %>%
        # filter to games released prior to current year
        filter(yearpublished < year(Sys.Date())) %>%
        # filter to games with at least X votes
        filter(usersrated >= min_ratings) %>%
        # set yearpublished to numeric
        mutate(yearpublished = as.numeric(yearpublished))

```

```{r functions and captions}

source(here::here("src", "functions", "explore_categorical_functions.R"))

# caption
my_caption = 
        list(labs(caption = paste(paste("data from boardgamegeek.com as of", max(as.Date(tidy_games$load_ts))),
                                  #    paste("analysis by phil henrickson"),
                                  paste("phenrickson.github.io/data-analysis-paralysis/boardgames.html"), sep="\n")))

```

This notebook provides some basic exploratory analysis of games on boardgamegeek (BGG) in support of my work [predicting ratings for upcoming games] and [predicting games for individual users]. 

For this write up, I examine games published through `r train_year` that have achieved at least `r min_ratings` user ratings by the time of writing.[^ I have additionally excluded some games that were cancelled or never released, or have data quality issues with their profiles on BGG.]

What are the designers of games on BGG and how do they relate to community ratings?

# Publishers

## Top Publishers by BGG Outcome

Which designers have published the most games on BGG? Which designers are the highest rated? Most popular? 

'Uncredited' is by far the most common listing for designer, so I have excluded it from the following visualization.

```{r most common designers, warning=F, message=F}

game_designers %>%
        filter(!(value %in% '(Uncredited)')) %>%
        group_by(type, id, value) %>%
        summarize(games = n_distinct(game_id),
                  .groups = 'drop') %>%
        slice_max(games, n = 50, with_ties=F) %>%
        arrange(desc(games)) %>%
        mutate(rank = row_number()) %>%
        mutate(page = case_when(rank %in% seq(1, 25) ~ "1-25",
                                rank %in% seq(26, 50) ~ "26-50")) %>%
        mutate(value = abbreviate(value, minlength=25)) %>%
        ggplot(aes(y=reorder(value,games),
                   x=games))+
        geom_col()+
        theme_phil()+
        theme(axis.text.y = element_text(size = 8),
              strip.text.x = element_text(size = 6))+
        facet_wrap(. ~ page,
                   scales = "free_y")+
        scale_x_continuous(breaks = scales::pretty_breaks(n=3))+
        ylab("Designer")+
        xlab("Number of Games")+
        my_caption
        

```

I'll then plot the distribution of games with the 25 most frequent designers. What designers are typically associated with heavier games? What designer is the highest rated (on average)?

```{r plot designers}

plot_games_by_categorical(game_designers,
                          alpha = 0.25,
                          25)

```

Finally, the following (interactive) table displays the mean of each BGG outcome by designer. Use the filters below the column names to filter through the table by designer or set a minimum number of games. 

```{r make summary table}

# summarize data
summary_data = game_designers %>%
        summarize_games_by_categorical()


# color gradients
colorRampDiv = colorRampPalette(c("red", "white", "lightskyblue1"))
blueRampSeq = colorRampPalette(c("white", "skyblue1"))
redRampSeq = colorRampPalette(c("white", "orange"))

# generate table
summary_data %>%
        make_categorical_summary_table()

```

## Designer Partial Effects

Which designers have the largest effect on a game's average? Users rated? 

We could simply look at the games published by each designer and then take their average rating/average number of user ratings. However, this doesn't account for the fact that some designers design more complex games than others, or that recently published games tend to have higher averages. 

To get an estimate of each designer's partial effect on an outcome, I regress

That is, which designer has the largest partial effect on a game's average rating conditional on 

```{r partial effects of designers}

dat = tidy_games %>%
        filter(yearpublished <= train_year) %>%
        left_join(., game_designers %>%
                          filter(game_id %in% tidy_games$game_id) %>%
                          group_by(type, id, value) %>%
                          mutate(num_games = n_distinct(game_id)) %>%
                          ungroup() %>%
                          filter(num_games >= 5) %>%
                          select(-load_ts),
                  by = c("game_id")) %>%
        # replace na in value with unknown
        mutate(value = replace_na(value, 'Unknown')) %>%
        # replace na with type
        mutate(type = 'designer') %>%
        mutate(display_value = value) %>%
        # use function to tidy
        tidy_categorical_variables()

dat_prepped = dat %>%
        transmute(game_id, 
                  name, 
                  yearpublished, 
                  bayesaverage,
                  usersrated = log(usersrated),
                  averageweight, 
                  average, 
               #   display_value,
                  value,
                  has_value) %>%
        pivot_wider(names_from = c("value"),
                    values_from = c("has_value"),
                    values_fill = 0) 

# model
# penalized
glmnet_reg_mod = parsnip::linear_reg(mixture = 0.5, 
                                     penalty = .001,
                                     engine = 'glmnet')

# specify grid for tuning
glmnet_grid <- tibble(penalty = 10^seq(-3, -1, 
                                       length.out = 20))

# folds for tuning
set.seed(1999)
folds = vfold_cv(dat_prepped,
                 strata = average,
                 folds = 5)

# specify regression metrics
reg_metrics<-metric_set(yardstick::rmse)

# control for resamples
keep_pred <- control_resamples(save_pred = TRUE, 
                               save_workflow = TRUE)
# recipe
rec = recipe(x = dat_prepped) %>%
        update_role(game_id,
                    name,
                    bayesaverage,
                    average,
                    usersrated,
                    yearpublished,
                    new_role = "id") %>%
        # add
        update_role(all_numeric(),
                    -has_role("id"),
                    new_role = "predictor") %>%
        # compress yearpublished
        # denote games published before 1900 with indiciator
        step_mutate(published_prior_1900 = dplyr::case_when(yearpublished < 1900 ~ 1,
                                                            TRUE ~ 0)) %>%
        # then truncate to post 1900
        step_mutate(year = case_when(yearpublished < 1900 ~ 1900,
                                     TRUE ~ yearpublished)) %>%
        # then, add spline for truncated yearpublished
        step_ns(yearpublished,
                deg_free = 9) %>%
        # remove zero variance predictors
        step_zv(all_predictors()) %>%
        # normalize
        step_normalize(all_predictors())

# workflow to predict average
wflow_average = workflow() %>%
        add_recipe(rec %>%
                           update_role(bayesaverage, 
                                       new_role = "outcome")) %>%
        add_model(glmnet_reg_mod)

# workflow to predict usersrated (logged)
wflow_usersrated = workflow() %>%
        add_recipe(rec %>%
                           update_role(usersrated, 
                                       new_role = "outcome")) %>%
        add_model(glmnet_reg_mod)

# fit at nested level
wflow_fits = dat_prepped %>%
        # average
        mutate(outcome = 'average') %>%
        nest(-outcome) %>%
        # select tuning parameter via cv
        mutate(best_tune = 
                       map(data,
                           ~ wflow_average %>%
                                   tune_grid(.x,
                                             resamples = folds) %>%
                                   select_best(.x, metric = 'rmse'))) %>%
        mutate(workflow = map2(data,
                               best_tune,
                               ~ wflow_average %>%
                                       finalize_workflow(parameters = .y) %>%
                                       fit(.x))) %>%
        mutate(fit = map(workflow,
                         ~ extract_fit_parsnip(.x))) %>%
        mutate(augmented = map2(workflow, data,
                                ~ augment(.x, .y))) %>%
        mutate(coefs = map(fit,
                           ~ tidy(.x))) %>%
        bind_rows(.,
                  dat_prepped %>%
                          # usersrated
                          mutate(outcome = 'usersrated') %>%
                          nest(-outcome) %>%
                          mutate(best_tune = 
                                         map(data,
                                             ~ wflow_usersrated %>%
                                                     tune_grid(.x,
                                                               resamples = folds) %>%
                                                     select_best(.x, metric = 'rmse'))) %>%
                          mutate(workflow = map2(data,
                                                 best_tune,
                                                 ~ wflow_usersrated %>%
                                                         finalize_workflow(parameters = .y) %>%
                                                         fit(.x))) %>%
                          mutate(fit = map(workflow,
                                           ~ extract_fit_parsnip(.x))) %>%
                          mutate(augmented = map2(workflow, data,
                                                  ~ augment(.x, .y))) %>%
                          mutate(coefs = map(fit,
                                             ~ tidy(.x))))

```

```{r extract coefficients, layout="l-body-outset"}

wflow_fits %>%
        select(outcome, coefs) %>%
        unnest() %>%
        mutate(estimate = case_when(outcome == 'usersrated' ~ (exp(estimate)-1)*100,
                                    TRUE ~ estimate)) %>%
        mutate_if(is.numeric, round, 3) %>%
        arrange(desc(estimate)) %>%
        filter(!grepl("yearpublished", term)) %>%
        left_join(., 
                  dat %>%
                          transmute(term = value,
                                    display_value) %>%
                          distinct,
                  by = c("term")) %>%
        filter(!is.na(display_value)) %>%
        mutate(term = case_when(is.na(display_value )~ term,
                                      TRUE ~ display_value)) %>%
        select(outcome, term, estimate) %>%
        rmarkdown::paged_table()

```



