---
title: "Comparing Boardgames via Unsupervised Learning"
output: 
  html_document:
    toc: TRUE #adds a Table of Contents
    number_sections: TRUE #number your headings/sections
    toc_float: TRUE #let your ToC follow you as you scroll
    keep_md: no
    fig.caption: yes
params:
  end_training_year: 2020
  min_ratings: 30
---

```{r global settings, echo=F, warning=F, message=F, results='hide'}

knitr::opts_chunk$set(echo = F,
                      error=F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

# load packages to be used
source(here::here("scripts/load_packages.R"))

# additional libraries
# parallel
library(doParallel)
library(parallelly)

# for stan
library(brms)
library(broom.mixed)

# load custom functions to be used
source(here::here("functions/theme_phil.R"))
source(here::here("functions/tidy_name_func.R"))
source(here::here("functions/pivot_and_dummy_types.R"))
source(here::here("functions/get_bgg_data_from_github.R"))
rm(a)

```

```{r flextable settings, echo=F, warning=F, message=F, results='hide'}

#library(webshot2)
library(flextable)
set_flextable_defaults(theme_fun = theme_alafoli,
                       font.color = "grey10",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```

```{r connect to big query and query tables we need, warning=F, message=F, results='hide'}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"

# authorize
bq_auth(email = "phil.henrickson@aebs.com")

# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

# query table of game info to most recent load
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.api_game_info
                              where timestamp = (SELECT MAX(timestamp) as most_recent FROM bgg.api_game_info)') %>%
        select(-starts_with("rank")) %>%
        mutate(numweights = as.numeric(numweights)) %>%
        mutate_at(c("averageweight",
                    "playingtime",
                    "minplaytime",
                    "maxplaytime",
                    "yearpublished"),
                  ~ case_when(. == 0 ~ NA_real_,
                              TRUE ~ .))

# ugh, made a mistake in the schema...

# create caption for plots
my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))),
                        paste("Data and analysis at https://phenrickson.github.io/data-analysis-paralysis/boardgames.html"), sep="\n")))


# long table with game type variables
game_types= DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.api_game_categories')

# get bgg today
bgg_today = get_bgg_data_from_github(Sys.Date()-1)

```

# What is this Analysis? {-}

This notebook details my approach to clustering board games and finding nearest neighbors.

For this analysis, we will restrict ourserlves to games published through `r params$end_training_year`. We will validate the performance of our models by evaluating their performance in predicting games published in `r params$end_training_year + 1`.

# The Data

```{r get categorical features}

# load in categorical features
categorical_features_selected = readr::read_rds(here::here("data", "categorical_features_selected.Rdata"))

# pivot and spread these out
game_types_pivoted =game_types %>%
        left_join(., categorical_features_selected %>%
                          select(type, id, value, tidied, selected),
                  by = c("type", "id", "value")) %>%
        filter(selected == 'yes') %>%
        select(game_id, type, value) %>%
        mutate(type_abbrev = substr(type, 1, 3)) %>%
        mutate(value = tolower(gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", value))))) %>%
        mutate(type = paste(type, value, sep="_")) %>%
        mutate(has_type = 1) %>%
        select(-value) %>%
        pivot_wider(names_from = c("type"),
                            values_from = c("has_type"),
                            id_cols = c("game_id"),
                            names_sep = "_",
                            values_fn = min,
                            values_fill = 0)

# now join
games_model = active_games %>%
        left_join(.,
                  game_types_pivoted,
                  by = "game_id") %>%
        filter((game_id %in% (bgg_today %>%
                                     pull(game_id)) |
                        yearpublished > params$end_training_year)) %>% # allow new games
        filter(game_id != 295564)

```

## Splitting Data

```{r prepare datasets for modeling, echo=T}

# get full dataset
games_full = games_model %>%
        mutate(dataset = case_when(yearpublished <= params$end_training_year ~ 'train',
                                   yearpublished == params$end_training_year+1 ~ 'validation',
                                   yearpublished >= params$end_training_year+2 ~ 'test')) 

# filter our training set to only games with at least n ratings
games_train = games_model %>% 
        filter(yearpublished <= params$end_training_year) 

games_validation = games_model %>%
        filter(yearpublished == params$end_training_year+1) %>%
        filter(usersrated > 1)

games_test =  games_model %>%
        filter(yearpublished == params$end_training_year+2) %>%
        filter(usersrated > 1)

rm(game_types_pivoted,
 #  game_types_selected,
   game_types)

```


```{r build recipe, echo=T}

# creating recipe with no formula or outcome specified yet
base_recipe = recipe(x = games_train) %>%
        update_role(all_numeric(),
                    new_role = "predictor") %>%
        step_mutate_at(c("averageweight"),
                         fn = ~ na_if(., 0),
                       skip = T) %>% # set to skip as this will be an outcome
        step_mutate_at(c("yearpublished",
                         "playingtime"),
                       fn = ~ na_if(., 0)) %>% # these variables come through as 0 if they are missing
        update_role(one_of("timestamp",
                           "yearpublished",
                      "game_id",
                      "name",
                      "numcomments",
                      "numweights",
                      "owned",
                      "trading",
                      "wanting",
                      "wishing",
                      "timestamp",
                      "average",
                      "bayesaverage",
                      "averageweight",
                      "usersrated",
                      "stddev"),
                      new_role = "id") %>%
        step_filter(!is.na(yearpublished)) %>%
        step_filter(!is.na(name)) %>%
        step_mutate(missing_minage = case_when(is.na(minage) ~ 1,
                                               TRUE ~ 0)) %>%
        step_mutate(missing_playtingtime = case_when(is.na(playingtime) ~ 1,
                                                     TRUE ~ 0)) %>%
        step_impute_median(playingtime,
                           maxplayers,
                           minage) %>% # medianimpute numeric predictors
        # step_mutate(published_prior_1950 = case_when(yearpublished<1950 ~ 1,
        #                                                TRUE ~ 0)) %>%
        step_mutate(minplayers = case_when(minplayers < 1 ~ 1,
                                                     minplayers > 10 ~ 10, # truncate
                                                     TRUE ~ minplayers),
                    maxplayers = case_when(maxplayers < 1 ~ minplayers,
                                                     maxplayers > 20 ~ 20,
                                                     TRUE ~ maxplayers)) %>%
        step_rm(minplaytime, 
                maxplaytime) %>%
        step_mutate(time_per_player = playingtime/ maxplayers) %>% # make time per player variable
        step_mutate_at(starts_with("category_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("mechanic_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("artist_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("designer_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("publisher_"),
                           fn = ~ replace_na(., 0)) %>%  
        step_mutate_at(starts_with("family_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate(number_mechanics = rowSums(across(starts_with("mechanic_"))),
                  #    number_artists = rowSums(across(starts_with("art_"))),
                      number_categories = rowSums(across(starts_with("category_")))) %>%
        step_zv(all_predictors()) %>%
        step_nzv(all_predictors(),
                   -starts_with("publisher_"),
                   -starts_with("artist_"),
                   -starts_with("designer_"),
                   freq_cut = 100/1) %>% 
        step_corr(all_predictors(),
                  threshold = 0.9) %>%
        step_mutate(published_prior_1900 = case_when(yearpublished < 1900 ~ 1,
                                                     TRUE ~ 0)) %>%
        step_mutate(published_prior_1950 = case_when(yearpublished < 1950 ~ 1,
                                                     TRUE ~ 0)) %>%
        step_mutate(trunc_yearpublished = case_when(yearpublished < 1950 ~ 1950,
                                              TRUE ~ yearpublished)) %>% # truncate
        update_role("yearpublished",
                    new_role = "id") %>%
        # step_mutate(cut_yearpublished= yearpublished) %>%
        # step_cut(cut_yearpublished,
        #                      breaks = seq(1970, 2010, 10),
        #                      include_outside_range = T) %>%
        step_mutate(cut_playingtime= playingtime) %>%
        step_cut(cut_playingtime,
                             breaks = c(15, 45, 90, 180),
                             include_outside_range = T) %>%
        update_role("playingtime",
                    new_role = "id") %>%
        step_dummy(all_nominal_predictors()) %>%
        step_log(time_per_player,
                   offset = 1) %>%
        step_dummy(all_nominal_predictors()) %>%
        step_zv(all_predictors()) %>% # remove features with no variance
        step_nzv(all_predictors(),
                   -starts_with("publisher_"),
                   -starts_with("artist_"),
                   -starts_with("designer_"),
                   freq_cut = 100/1) %>% # apply near zero variance filter
        step_nzv(starts_with("artist_"),
          #       -one_of(c("artist_ian_otoole",
           #                "artist_chris_quilliams")), # allow for some specific artists, well known in recent years
                 freq_cut = 250/1) %>%
        step_corr(all_predictors(),
                  threshold = 0.9) %>% # remove highly, highly correlated features 
        update_role(
                c("averageweight"),
                new_role = "predictor") %>% #
        step_impute_linear(averageweight,
                           impute_with = imp_vars(
                                   all_numeric_predictors(),
                                   -starts_with("publisher_"),
                                   -starts_with("artist_"),
                                   starts_with("designer_"),
                                   )) 

```

# Dimension Reduction via PCA

I'm first interested in exploring using PCA for dimension reduction to learn more about the main points of variation in the data.

I'll then create an additional recipe on top of this that normalizes the data for PCA at the end. I'll define a recipe for a PCA given a specified list of features. I'm mainly trying to avoid features about the theme of the game, focusing instead on features that tell us something about how the game plays.

```{r build out recipe with pca, echo=T}

# pca focusing on fundamentals + mechanics
pca_mechanics_recipe = base_recipe %>%
        step_rm(starts_with("trunc_yearpublished"),
                starts_with("number_categories"),
                starts_with("artist"),
                starts_with("designer_"),
                starts_with("publisher_"),
                starts_with("published_"),
                starts_with("category_book"),
                starts_with("category_mafia"),
                starts_with("category_horror"),
                starts_with("category_trains"),
                starts_with("category_comic_book_strip"),
            #    starts_with("category_racing"),
                starts_with("category_book"),
                starts_with("category_sports"),
                starts_with("category_trains"),
                starts_with("category_travel"),
                starts_with("category_trivia"),
                starts_with("category_ancient"),
                starts_with("category_animals"),
                starts_with("category_fantasy"),
                starts_with("category_farming"),
                starts_with("category_pirates"),
              #  starts_with("category_wargame"),
                starts_with("category_zombies"),
             #   starts_with("category_bluffing"),
                starts_with("category_economic"),
             #   starts_with("category_fighting"),
                starts_with("category_medieval"),
                starts_with("category_nautical"),
                starts_with("category_adventure"),
                starts_with("category_civil_war"),
         #       starts_with("category_deduction"),
                starts_with("category_mythology"),
                starts_with("category_political"),
                starts_with("category_religious"),
                starts_with("category_electronic"),
                starts_with("category_napoleonic"),
                starts_with("category_educational"),
                starts_with("category_exploration"),
                starts_with("category_novelbased"),
                starts_with("category_prehistoric"),
                starts_with("category_renaissance"),
                starts_with("category_world_war_i"),
                starts_with("category_world_war_ii"),
                starts_with("category_civilization"),
                starts_with("category_age_of_reason"),
                starts_with("category_american_west"),
                starts_with("category_city_building"),
                starts_with("category_environmental"),
                starts_with("category_mature_adult"),
                starts_with("category_modern_warfare"),
                starts_with("category_murdermystery"),
                starts_with("category_transportation"),
                starts_with("category_postnapoleonic"),
                starts_with("category_science_fiction"),
                starts_with("category_video_game_theme"),
                starts_with("category_aviation_flight"),
                starts_with("category_space_exploration"),
                starts_with("category_american_civil_war"),
                starts_with("cateogry_comic_book_strip"),
                starts_with("category_territory_building"),
                starts_with("category_spiessecret_agents"),
                starts_with("category_industry_manufacturing"),
                starts_with("category_movies_tv_radio_theme"),
                starts_with("family_ancient_rome"),
                starts_with("family_animals_cats"),
                starts_with("family_brands_"),
                starts_with("family_continents_"),
                starts_with("family_country_"),
                starts_with("family_creatures_"),
                starts_with("family_crowdfunding"),
                starts_with("family_history_"),
                starts_with("family_magazine_"),
                starts_with("family_movies_"),
                starts_with("family_sports_"),
                starts_with("family_theme_"),
            starts_with("family_components_"),
                starts_with("family_word_")) %>%
        step_normalize(all_numeric_predictors()) %>%
        step_pca(all_numeric_predictors(), 
                 id = "pca",
                 num_comp = 500)

# # pca using categories and family variables as well
# pca_categories_recipe = base_recipe %>%
#         step_rm(starts_with("trunc_yearpublished"),
#                 starts_with("artist_"),
#                 starts_with("designer_"),
#                 starts_with("publisher_"),
#                 starts_with("published_")) %>%
#         step_normalize(all_numeric_predictors()) %>%
#         step_pca(all_numeric_predictors(), 
#                  id = "pca",
#                  num_comp = 500)
                        
```

We can then bake these recipes on the training set.

```{r bake pca, echo=T}

# # prep recipe for categories
# pca_categories_trained = pca_categories_recipe %>%
#         prep(games_train)

# prep recipes for mechanics
pca_mechanics_trained = pca_mechanics_recipe %>%
        prep(games_train)

# # extract componenbts from each of these
# pca_categories_components = pca_categories_trained %>%
#         tidy(id = "pca") %>%
#         mutate(component = gsub("PC0", "PC", gsub("PC00", "PC", component)))

pca_mechanics_components = pca_mechanics_trained %>%
        tidy(id = "pca") %>%
        mutate(component = gsub("PC0", "PC", gsub("PC00", "PC", component)))

```

## PCA Loadings

```{r  plot the first two main principal components for components, warning=F}

# define arrow style
arrow_style <- arrow(length = unit(.05, "inches"),
                     type = "closed")

# pca_loadings
pca_wider = pca_mechanics_components %>%
          tidyr::pivot_wider(names_from = component, id_cols = terms)

# make plot
pca_mechanics_components %>%
        filter(id == 'pca') %>%
        mutate(abs_value = abs(value)) %>%
        tidyr::pivot_wider(names_from = component, id_cols = terms) %>%
        arrange(desc(abs(PC1))) %>%
        mutate(terms = tidy_name_func(terms)) %>%
        head(100) %>%
        ggplot(., aes(x=PC1, 
                y=PC2))+
        geom_segment(alpha=0.5,
                     aes(xend = PC1, yend = PC2), 
                     x = 0, y = 0, 
                     color = 'grey60',
               arrow = arrow_style)+
          geom_text(aes(x = PC1, y = PC2, label = terms), 
                    check_overlap=T,
            hjust = 0, 
            vjust = 1,
            size = 3)+
        my_caption+
        xlab("First Principal Component")+
        ylab("Second Principal Component")+
        geom_vline(xintercept = 0,
                   linetype = 'dashed')+
        geom_hline(yintercept = 0,
                   linetype = 'dashed')+
        theme_phil()
 
```

Based on this, we get groupings with wargames occupying the right/upper right, then more thematic games down the bottom middle, party games in the bottom left, and abstracts/card games in the upper left.

```{r plot component loadings for mechanics, fig.height=8, fig.width=10}

pca_mechanics_rotation = pca_mechanics_trained %>%
        prep(games_train) %>%
        bake(new_data = NULL) %>%
        set_names(., gsub("PC0", "PC", gsub("PC00", "PC", names(.))))

pca_mechanics_rotation %>%
        ggplot(., aes(x=PC1, 
                label = name,
                y=PC2))+
        geom_point(alpha=0.15)+
        geom_text(check_overlap = T,
             size = 2,
             vjust = -1)+
        #   position=position_jitter(width=0.2,height=0.2))+
        theme_phil()+
        my_caption+
        xlab("First Principal Component")+
        ylab("Second Principal Component")+
        geom_vline(xintercept = 0,
                   linetype = 'dashed')+
        geom_hline(yintercept =0,
                   linetype = 'dashed')
        # facet_zoom(xlim = c(2, 5),
        #            ylim = c(-2, -5))
        # annotate("label",
        #          label = "Complex, Thematic",
        #          color = 'blue',
        #          x = 9,
        #          y = -8)+
        # annotate("label",
        #          label = "Abstract",
        #          color = 'blue',
        #          x = -4,
        #          y = 5)+
        # annotate("label",
        #          label = "Party, Social Deduction",
        #          color = 'blue',
        #          x = -5,
        #          y = -5)+
        # annotate("label",
        #          label = "Wargames/Simulation",
        #          color = 'blue',
        #          x = 10,
        #          y = 7)+
        # coord_cartesian(xlim = c(-7, 15),
        #                 ylim = c(-14, 8))

```

How well does each dimension summarize the variation in the data? We can use a scree plot to examine the percentage of variation explained by each component as well as the cumulative variation as we up the number of compnents.

```{r show scree plot for mechanics}

pca_mechanics_trained %>%
        tidy(id = "pca",
             type = "variance") %>%
        mutate(outcome = "fundamentals, mechanics") %>%
        filter(terms %in% c("percent variance",
                            "cumulative percent variance")) %>%
        ggplot(., aes(x=component,
                      y=value))+
        geom_col()+
        facet_grid(terms ~ outcome,
                #   ncol =1,
                   scales = "free")+
        theme_phil()

```

Here, the first few components explain more of the variation, and it takes about 7 components to explain 25% of the overall variation in the dataset.

What contributes to each of those components? We can plot the top 20 variables that contribute the most to each component for the first 10 principal components.

```{r pca loadings for top ten components}

number_pcs = paste("PC", seq(1, 10, 1), sep="")

pca_mechanics_components %>%
        filter(component %in% number_pcs) %>%
        mutate(component = factor(component,
                                  levels = number_pcs)) %>%
        group_by(component) %>%
        slice_max(.,
                  order_by = abs(value),
                  n = 10,
                  with_ties = F) %>%
        mutate(terms = tidy_name_func(terms)) %>%
        ggplot(., aes(x=value,
                      fill = value,
                      y = reorder_within(terms, value, component)))+
        geom_col()+
        facet_wrap(component~.,
                   scales = "free_y",
                   ncol = 2)+
        theme_bw(8)+
        scale_y_reordered()+
        scale_fill_viridis()+
        guides(fill = "none")+
        ylab("")

```

```{r remove unnecessary objects from memory, warning=F, message=F}

rm(games_model,
   categorical_features_selected,
   pca_wider,
   base_recipe)

```

# Nearest Neighbors

## Create Functions

Once we've computed the principal components using the different sets of features, we can get the distance between all observations in order to find each game's nearest neighbors. We could use Euclidean or Manhattan distance, but I'm using cosine similarity to measure the similarity as I think we care more about the angle than the magnitude when trying to figure out which games are similar to each other (I've mostly found them to be the same in practice).

```{r functions for nearest neighbors}

# custom n.min function
n_min_func <- function(row, n) {
        neighbors = order(row)[1:n]
        data.frame(neighbor = neighbors,
                   dist = row[neighbors])
}

# custom n.min function
n_max_func <- function(row, n) {
        neighbors = rev(order(row))[1:n]
        data.frame(neighbor = neighbors,
                   dist = row[neighbors])
}

# get distances
get_dist_func = function(input_data, select_method) {
        
        dist(input_data %>%
                     select_if(is.numeric) %>%
                     as.matrix(),
             method=paste0(select_method)) %>%
                as.matrix()
        
}

# cosine distance
library(lsa)
library(REdaS)

# cosine similarity
dist_cosine_func = function(input_mat) {
        
        Matrix <- as.matrix(input_mat)
        sim <- Matrix / sqrt(rowSums(Matrix * Matrix))
        out <- sim %*% t(sim)
        
}

# euclidean distance
dist_euclidean_func = function(input_mat) {
        
      dist =  dist(input_mat,
             method = "euclidean")
      out = dist %>%
              as.matrix()
        
}

# get neighbors from a distance matrix
find_neighbors_min_func = function(input_dist, num_neighbors) {
        apply(input_dist, 1, n_min_func, n = num_neighbors) %>%
                        rbindlist(idcol = T) %>%
                set_names(., c(".row", ".row_neighbor", "dist")) %>%
                mutate(.row = as.integer(.row),
                       .row_neighbor = as.integer(.row_neighbor))
             #   filter(dist > 0)
}

# get neighbors from a distance matrix
find_neighbors_max_func = function(input_dist, num_neighbors) {
        apply(input_dist, 1, n_max_func, n = num_neighbors) %>%
                        rbindlist(idcol = T) %>%
                set_names(., c(".row", ".row_neighbor", "dist")) %>%
                mutate(.row = as.integer(.row),
                       .row_neighbor = as.integer(.row_neighbor))
             #   filter(dist > 0)
}

```


```{r get cosine distances}

# first number of PCs that summarizes 50% of the variation
number_pcs = paste("PC", seq(1, 25), sep="")

# # all
# number_pcs = pca_mechanics_rotation %>% 
#         select(starts_with("PC")) %>% names()

# get a matrix where each row is one game's values on the first two principal compnents
pca_mat = pca_mechanics_rotation %>%
        mutate(.row = row_number()) %>%
        select(.row, starts_with("PC")) %>%
        select(.row, all_of(number_pcs)) %>%
        column_to_rownames(".row") %>%
        as.matrix()

# get cosine similarity
dist_cosine = dist_cosine_func(pca_mat)

# get euclidean distance
dist_euclidean = dist_euclidean_func(pca_mat)

# get neighbors from cosine
neighbors_cosine = find_neighbors_max_func(dist_cosine, 51) %>%
        left_join(., games_train %>%
                          mutate(.row = row_number()) %>%
                          select(.row, game_id, name, average, bayesaverage),
                  by = c(".row")) %>%
        left_join(., games_train %>%
                          mutate(.row_neighbor = row_number(),
                                 neighbor_id = game_id,
                                 neighbor_name = name,
                                 neighbor_average = average,
                                 neighbor_bayesaverage = bayesaverage) %>%
                          select(.row_neighbor, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage),
                  by = c(".row_neighbor"))


# get neighbors from euclidean
neighbors_euclidean = find_neighbors_min_func(dist_euclidean, 51) %>%
        left_join(., games_train %>%
                          mutate(.row = row_number()) %>%
                          select(.row, game_id, name, average, bayesaverage),
                  by = c(".row")) %>%
        left_join(., games_train %>%
                          mutate(.row_neighbor = row_number(),
                                 neighbor_id = game_id,
                                 neighbor_name = name,
                                 neighbor_average = average,
                                 neighbor_bayesaverage = bayesaverage) %>%
                          select(.row_neighbor, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage),
                  by = c(".row_neighbor"))


```

What is the distribution of cosine similarity for a sample of 1000 games? What about euclidean distance?

```{r distribution of cosine similarity}

# make histogram
hist(dist_cosine[sample(1:nrow(pca_mat), 1000),],
     main="",
     xlab = "cosine similarity")

# make histogram
hist(dist_euclidean[sample(1:nrow(pca_mat), 1000),],
     main="",
     xlab = "euclidean distance")


#quantile(dist_cosine, probs = c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, .99))

```

Let's look at the neighbors for a sample of games.

```{r get all neighbors for a sample of games}

samp_rows = games_train %>% 
        mutate(.row = row_number()) %>% 
        filter(name == 'Twilight Imperium: Fourth Edition' |
                       name == 'Spyfall' |
                       name == 'Nemesis' |
                       name == 'Catan' |
                       name == 'Inis' | 
                       name == 'A Feast for Odin' |
                       name == 'Burgle Bros.' | 
                       name == 'Azul' |
                       name == 'Gloomhaven' |
                       name == 'Parade' | 
                       name == 'Terra Mystica'|
                       name == 'Troyes'| 
                       name == 'Monopoly' |
                       name == 'Brass: Birmingham' |
                       name == 'Great Western Trail' |
                       name == 'Dinosaur Island' |
                       name == 'On Mars' |
                       name == 'Scythe' |
                       name == 'Splendor' |
                       name == 'Tiny Towns' |
                       name == 'Spirit Island' |
                       name == '7 Wonders' |
                       name == 'The Quest for El Dorado' |
                       name == 'Wingspan' |
                       name == 'Irish Gauge' |
                       name == 'Dead of Winter: A Crossroads Game' |
                       name == 'Terraforming Mars' |
                       name == 'Yokohama' | 
                       name == 'The Quacks of Quedlinburg'
               ) %>% 
        select(.row, name) %>%
        pull(.row)

samp_neighbors_cosine = find_neighbors_max_func(dist_cosine[samp_rows,], ncol(dist_cosine)) %>%
           left_join(., games_train %>%
                          mutate(.row = row_number()) %>%
                          select(.row, game_id, name, average, bayesaverage),
                  by = c(".row")) %>%
        left_join(., games_train %>%
                          mutate(.row_neighbor = row_number(),
                                 neighbor_id = game_id,
                                 neighbor_name = name,
                                 neighbor_average = average,
                                 neighbor_bayesaverage = bayesaverage) %>%
                          select(.row_neighbor, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage),
                  by = c(".row_neighbor")) %>%
        rename(similarity = dist) %>%
        mutate(score = similarity * neighbor_bayesaverage) %>%
        mutate_if(is.numeric, round, 2) %>%
        as_tibble() %>%
        filter(name != neighbor_name)

samp_neighbors_euclidean = find_neighbors_min_func(dist_euclidean[samp_rows,], ncol(dist_euclidean)) %>%
           left_join(., games_train %>%
                          mutate(.row = row_number()) %>%
                          select(.row, game_id, name, average, bayesaverage),
                  by = c(".row")) %>%
        left_join(., games_train %>%
                          mutate(.row_neighbor = row_number(),
                                 neighbor_id = game_id,
                                 neighbor_name = name,
                                 neighbor_average = average,
                                 neighbor_bayesaverage = bayesaverage) %>%
                          select(.row_neighbor, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage),
                  by = c(".row_neighbor")) %>%
     #   rename(similarity = dist) %>%
     #   mutate(score = similarity * neighbor_bayesaverage) %>%
        mutate_if(is.numeric, round, 2) %>%
        as_tibble() %>%
        filter(name != neighbor_name)

```


```{r samp neighbors examine}

temp = 'Inis'

samp_neighbors_cosine %>%
        select(game_id, name, similarity, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage, score) %>%
        filter(name == temp) %>%
        head(50) %>%
        arrange(desc(score)) %>%
        rename(`similarity*bayesaverage` = score)  

samp_neighbors_euclidean%>%
        select(game_id, name, dist, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage) %>%
        arrange(dist) %>%
        filter(name == temp) %>%
        head(50)

```

```{r rm what we dont need, warning=F, message=F}

rm(dist_cosine,
   dist_euclidean,
   samp_neighbors_cosine,
   samp_neighbors_euclidean,
   neighbors_cosine,
   neighbors_euclidean,
   pca_mat)

```


## Apply to Validation & Test Set

Now apply the PCA learned on the training set to games in the validation and test sets - for now, restricting to games that have obtained at least 5 user ratings.

```{r now prep on train and bake validation set}

# prep on train, bake on train + validation + test
pca_trained = pca_mechanics_recipe %>%
        prep(games_train, strings_as_factor = F) %>%
        bake(new_data = bind_rows(games_train,
                       games_validation,
                       games_test)) %>%
        set_names(., gsub("PC0", "PC", gsub("PC00", "PC", names(.))))

# save
save(pca_mechanics_recipe,
     file = here::here("models", "repository", paste("pca_recipe_", Sys.Date(), ".Rds", sep="")))

save(pca_trained,
     file = here::here("models", "repository", paste("pca_trained_", Sys.Date(), ".Rds", sep="")))

```


```{r now apply our distance functions}

# number_pcs = pca_mechanics_rotation %>% 
#         select(starts_with("PC")) %>% names()

# get a matrix where each row is one game's values on the first two principal compnents
pca_mat = pca_trained %>%
        mutate(.row = row_number()) %>%
        select(.row, starts_with("PC")) %>%
        select(.row, all_of(number_pcs)) %>%
        column_to_rownames(".row") %>%
        as.matrix()

# get cosine similarity
dist_cosine = dist_cosine_func(pca_mat)

# get neighbors from cosine
neighbors_cosine = find_neighbors_max_func(dist_cosine, 51) %>%
        left_join(., pca_trained %>%
                          mutate(.row = row_number()) %>%
                          select(.row, game_id, name, average, bayesaverage),
                  by = c(".row")) %>%
        left_join(., pca_trained %>%
                          mutate(.row_neighbor = row_number(),
                                 neighbor_id = game_id,
                                 neighbor_name = name,
                                 neighbor_average = average,
                                 neighbor_yearpublished = yearpublished,
                                 neighbor_bayesaverage = bayesaverage) %>%
                          select(.row_neighbor, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage, neighbor_yearpublished, starts_with("PC")),
                  by = c(".row_neighbor")) %>%
        rename(similarity = dist) %>%
        mutate(score = similarity*neighbor_bayesaverage)

# save neighbors object
save(neighbors_cosine,
     file = here::here("data", "game_neighbors_cosine.Rds"))

```



```{r tile plot func, fig.width=10, fig.height=8}

tile_plot = function(neighbors_cosine,
                           input_pcs,
                           input_game_id) {
        
        # create vector
        number_pcs = paste("PC", seq(1, input_pcs), sep="")

        # make initial plot
        dat =  neighbors_cosine %>%
                filter(game_id == input_game_id) %>%
         #       arrange(desc(score)) %>%
                mutate(neighbor_name = abbreviate(neighbor_name, 60)) %>%
                group_by(neighbor_name) %>% mutate(count = n()) %>%
                ungroup() %>%
                mutate(neighbor_name = case_when(count > 1 ~ paste(neighbor_name, neighbor_yearpublished, sep="_"),
                       TRUE ~ neighbor_name))
        
        #return(dat)
                
        dat %>%
                select(neighbor_id, neighbor_name,
                       all_of(number_pcs)) %>%
                gather("component", "value",
                       -neighbor_id, -neighbor_name) %>%
                mutate(neighbor_name = factor(neighbor_name,
                                              levels = rev(dat %>% select(neighbor_name) %>% pull()))) %>%
                mutate(component = factor(component,
                                          levels = number_pcs)) %>%
                mutate(highlight = case_when(neighbor_id == input_game_id ~ 'yes',
                                             TRUE ~ 'no')) %>%
                ggplot(., aes(y=neighbor_name,
                           #   color = highlight,
                              label = round(value, 2),
                              fill = value,
                              x=component))+
                geom_tile()+
                geom_text(color = 'white', size=3)+
                # scale_fill_viridis(limits = c(-8, 8),
                #                    oob = scales::squish)+
                # scale_fill_viridis(option = "A",
                #                    limits = c(-8,8),
                #                    oob = scales::squish)+
                scale_fill_gradient2(low = "orange",
                                     mid = "grey80",
                                     high = "navy",
                                     limits = c(-6, 6),
                                     oob = scales::squish)+
                # scale_fill_viridis(option = "B",
                #                    scale = )+
                theme_phil()+
                theme(legend.title = element_text()) +
                guides(fill = guide_colorbar(barwidth=10,
                                             barheight=0.5,
                                             title = "Component Score",
                                             title.position = 'top'),
                       color = "none")+
                scale_color_manual(values = c("white", "black"))
                           
}

```


```{r tile plot example, fig.height=8, fig.width=10, warning=F}

tile_plot(neighbors_cosine,
          25,
          active_games %>% filter(name == 'Root') %>% pull(game_id)) +
        ylab("Games")

```



```{r now look to find}, fig.height=10, fig.width=6}

neighbors_cosine %>%
        rename(similarity = dist) %>%
        mutate(score = similarity * neighbor_bayesaverage) %>%
        select(game_id, name, similarity, neighbor_id, neighbor_name, neighbor_average, neighbor_bayesaverage, score) %>%
        filter(name == 'Unfathomable') %>%
        head(50) %>%
        arrange(desc(score)) %>%
        rename(`similarity*bayesaverage` = score) %>%
        mutate_if(is.numeric, round, 2) %>%
        arrange(desc(similarity))

samp_ids = neighbors_cosine %>%
        filter(name == 'Unfathomable') %>%
        select(neighbor_id) %>%
        pull() %>%
        unique()

tile_plot(pca_mechanics_with_validation,
          25,
           input_game_id = samp_ids)


```
