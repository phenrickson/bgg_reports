---
title: "Examining BGG Designers"
author: Phil Henrickson
params:
        train_year: 2020
        min_ratings: 50
---

```{r setup, inclue=F, results = 'hide', message=F, warning=F}

source(here::here("src", "helpers", "exploratory_setup.R"))

```

```{r load functions for categorical, include=F} 

source(here::here("src", "functions", "categorical_functions.R"))

```


```{r create tidy games, include=F}

# set minimum ratings
min_ratings = params$min_ratings

# train year
train_year = params$train_year

# remove unreleased and problem games
tidy_games =
        analysis_games %>%
        # remove unreleased and problem games
        filter(!(game_id %in% c(
                unreleased_games$game_id,
                drop_games$game_id))
        ) %>%
        # filter out games with missingness on yearpublished
        filter(!is.na(yearpublished)) %>%
        # filter out games with missingness on average weight
        filter(!is.na(averageweight) & averageweight!=0) %>%
        # filter our kickstarter editions and big box editions
      #  filter(!(grepl("kickstarter|big box|mega box|megabox", tolower(name)))) %>%
        # filter to games released prior to current year
        filter(yearpublished < year(Sys.Date())) %>%
        # filter to games with at least X votes
        filter(usersrated >= min_ratings) %>%
        # set yearpublished to numeric
        mutate(yearpublished = as.numeric(yearpublished))

```

```{r functions and captions}

# caption
my_caption = 
        list(labs(caption = paste(paste("data from boardgamegeek.com as of", max(as.Date(tidy_games$load_ts))),
                                  #    paste("analysis by phil henrickson"),
                                  paste("phenrickson.github.io/data-analysis-paralysis/boardgames.html"), sep="\n")))

```

This notebook provides some basic exploratory analysis of games on boardgamegeek (BGG) in support of my work [predicting ratings for upcoming games] and [predicting games for individual users]. 

For this write up, I examine games published through `r train_year` that have achieved at least `r min_ratings` user ratings by the time of writing.[^ I have additionally excluded some games that were cancelled or never released, or have data quality issues with their profiles on BGG.]

What are the designers of games on BGG and how do they relate to community ratings?

# Designers

## Top Designers by BGG Outcome

Which designers have published the most games on BGG? Which designers are the highest rated? Most popular? 

'Uncredited' is by far the most common listing for designer, so I have excluded it from the following visualization.

```{r most common designers, warning=F, message=F}

game_designers %>%
        filter(!(value %in% '(Uncredited)')) %>%
        group_by(type, id, value) %>%
        summarize(games = n_distinct(game_id),
                  .groups = 'drop') %>%
        slice_max(games, n = 50, with_ties=F) %>%
        arrange(desc(games)) %>%
        mutate(rank = row_number()) %>%
        mutate(page = case_when(rank %in% seq(1, 25) ~ "1-25",
                                rank %in% seq(26, 50) ~ "26-50")) %>%
        mutate(value = abbreviate(value, minlength=25)) %>%
        ggplot(aes(y=reorder(value,games),
                   x=games))+
        geom_col()+
        theme_phil()+
        theme(axis.text.y = element_text(size = 8),
              strip.text.x = element_text(size = 6))+
        facet_wrap(. ~ page,
                   scales = "free_y")+
        scale_x_continuous(breaks = scales::pretty_breaks(n=3))+
        ylab("Designer")+
        xlab("Number of Games")+
        my_caption


```

I'll then plot the distribution of games with the 25 most frequent designers. What designers are typically associated with heavier games? What designer is the highest rated (on average)?

```{r plot designers}

plot_games_by_categorical(game_designers,
                          alpha = 0.25,
                          25)

```

Finally, the following (interactive) table displays the mean of each BGG outcome by designer. Use the filters below the column names to filter through the table by designer or set a minimum number of games. 

```{r make summary table}

# summarize data
summary_data = game_designers %>%
        summarize_games_by_categorical()


# color gradients
colorRampDiv = colorRampPalette(c("red", "white", "lightskyblue1"))
blueRampSeq = colorRampPalette(c("white", "skyblue1"))
redRampSeq = colorRampPalette(c("white", "orange"))

# generate table
summary_data %>%
        make_categorical_summary_table()

```

## Designer Partial Effects

Which designers have the largest effect on a game's average? User ratings?

We could simply look at the games published by each designer and then take their average rating/average number of user ratings. However, this doesn't account for the fact that some designers design more complex games than others, or that recently published games tend to have higher averages. 

To get an estimate of each designer's partial effect on an outcome, I run penalized regressions lasso) of the BGG average/usersrated on dummies for individual game designers along with the game's weight and effects for year published [^ I handle time effects in two different ways, first creating an indicator for games published before 1900, then fitting cubic splines to the truncated publishing range of years 1900 to present].

$$ Average = \beta_0 + Weight * \beta_1 + Designer_i * \beta_2 + Designer_j * \beta_3 * Designer_k ... Designer_n * \beta_n + YearPublished $$
```{r partial effects of designers, include=F}

dat = tidy_games %>%
        filter(yearpublished <= train_year) %>%
        left_join(., game_designers %>%
                          filter(game_id %in% tidy_games$game_id) %>%
                          group_by(type, id, value) %>%
                          mutate(num_games = n_distinct(game_id)) %>%
                          ungroup() %>%
                          filter(num_games >= 5) %>%
                          select(-load_ts),
                  by = c("game_id")) %>%
        # replace na in value with unknown
        mutate(value = replace_na(value, 'Unknown')) %>%
        # replace na with type
        mutate(type = 'designer') %>%
        mutate(display_value = value) %>%
        # use function to tidy
        tidy_categorical_variables()

dat_prepped = dat %>%
        transmute(game_id, 
                  name, 
                  yearpublished, 
                  bayesaverage,
                  usersrated = log(usersrated),
                  averageweight, 
                  average, 
                  #   display_value,
                  value,
                  has_value) %>%
        pivot_wider(names_from = c("value"),
                    values_from = c("has_value"),
                    values_fill = 0) 

# model
# penalized regression
glmnet_reg_mod = parsnip::linear_reg(mixture = 1, 
                                     penalty = tune::tune(),
                                     engine = 'glmnet')

# specify grid for tuning
glmnet_grid <- tibble(penalty = 10^seq(-3, -1, 
                                       length.out = 20))

# poisson regression
# library(poissonreg)
# pois_reg_mod = parsnip::poisson_reg(mode = "regression",
#                                     mixture = 0.5,
#                                     penalty = tune::tune(),
#                                     engine = 'glmnet')

# folds for tuning
set.seed(1999)
folds = vfold_cv(dat_prepped,
                 strata = usersrated,
                 v = 5)

# specify regression metrics
reg_metrics<-metric_set(yardstick::rmse)

# control for resamples
keep_pred <- control_resamples(save_pred = TRUE, 
                               save_workflow = TRUE)
# recipe
rec = recipe(x = dat_prepped) %>%
        update_role(game_id,
                    name,
                    bayesaverage,
                    average,
                    usersrated,
                    yearpublished,
                    new_role = "id") %>%
        # add
        update_role(all_numeric(),
                    -has_role("id"),
                    new_role = "predictor") %>%
        # compress yearpublished
        # denote games published before 1900 with indiciator
        step_mutate(published_prior_1900 = dplyr::case_when(yearpublished < 1900 ~ 1,
                                                            TRUE ~ 0)) %>%
        # then truncate to post 1900
        step_mutate(year = case_when(yearpublished < 1900 ~ 1900,
                                     TRUE ~ yearpublished)) %>%
        # then, add spline for truncated yearpublished
        step_ns(yearpublished,
                deg_free = 9) %>%
        # then, convert averageweight to 0 1
        step_range(averageweight, min = 0, max =1) %>%
        # remove zero variance predictors
        step_zv(all_predictors())

# workflow to predict average
wflow_average = workflow() %>%
        add_recipe(rec %>%
                           update_role(bayesaverage, 
                                       new_role = "outcome")) %>%
        add_model(glmnet_reg_mod)

# workflow to predict usersrated (logged)
wflow_usersrated = workflow() %>%
        add_recipe(rec %>%
                           update_role(usersrated, 
                                       new_role = "outcome")) %>%
        add_model(glmnet_reg_mod)

# fit at nested level
wflow_fits = dat_prepped %>%
        # average
        mutate(outcome = 'average') %>%
        nest(-outcome) %>%
        # select tuning parameter via cv
        mutate(best_tune = 
                       map(data,
                           ~ wflow_average %>%
                                   tune_grid(.x, 
                                             resamples = folds) %>%
                                   select_best(.x, metric = 'rmse'))) %>%
        mutate(workflow = map2(data,
                               best_tune,
                               ~ wflow_average %>%
                                       finalize_workflow(parameters = .y) %>%
                                       fit(.x))) %>%
        mutate(fit = map(workflow,
                         ~ extract_fit_parsnip(.x))) %>%
        mutate(augmented = map2(workflow, data,
                                ~ augment(.x, .y))) %>%
        mutate(coefs = map(fit,
                           ~ tidy(.x))) %>%
        bind_rows(.,
                  dat_prepped %>%
                          # usersrated
                          mutate(outcome = 'usersrated') %>%
                          nest(-outcome) %>%
                          mutate(best_tune = 
                                         map(data,
                                             ~ wflow_usersrated %>%
                                                     tune_grid(.x,
                                                               resamples = folds) %>%
                                                     select_best(.x, metric = 'rmse'))) %>%
                          mutate(workflow = map2(data,
                                                 best_tune,
                                                 ~ wflow_usersrated %>%
                                                         finalize_workflow(parameters = .y) %>%
                                                         fit(.x))) %>%
                          mutate(fit = map(workflow,
                                           ~ extract_fit_parsnip(.x))) %>%
                          mutate(augmented = map2(workflow, data,
                                                  ~ augment(.x, .y))) %>%
                          mutate(coefs = map(fit,
                                             ~ tidy(.x))))

```

```{r extract coefficients and make table, layout="l-body-outset"}

seq_average = seq(-2, 2, .05)
seq_usersrated = seq(-1, 50, .5)

wflow_fits %>%
        select(outcome, coefs) %>%
        unnest() %>%
        filter(!grepl("yearpublished|averageweight|Intercept", term)) %>%
        mutate(estimate = case_when(outcome == 'usersrated' ~ (exp(estimate)-1),
                                    TRUE ~ estimate)) %>%
        mutate_if(is.numeric, round, 3) %>%
        # get display name
        arrange(desc(estimate)) %>%
        left_join(.,
                  dat %>%
                          transmute(term = value,
                                    display_value,
                                    num_games) %>%
                          distinct,
                  by = c("term")) %>%
        filter(!is.na(display_value)) %>%
        mutate(term = case_when(is.na(display_value )~ term,
                                TRUE ~ display_value)) %>%
        select(num_games, outcome, term, estimate) %>%
        # pivot
        pivot_wider(names_from = c("outcome"),
                    values_from = c("estimate")) %>%
        # round usersrated
        mutate(usersrated = round(usersrated, 2)) %>%
        arrange(desc(num_games)) %>%
        transmute(Designer = term,
                  Games = num_games,
                  Average = average,
                  Ratings = usersrated) %>%
        DT::datatable(escape=F,
                      rownames = F,
                      extensions = c('Responsive'),
                      #    caption = 'ZoomInfo Companies - Client Probabilities by COE',
                      filter = list(position = 'top'),
                      options = list(pageLength = 15,
                                     initComplete = htmlwidgets::JS(
                                             "function(settings, json) {",
                                             paste0("$(this.api().table().container()).css({'font-size': '", '8pt', "'});"),
                                             "}"),
                                     scrollX=F,
                                     columnDefs = list(
                                             list(className = 'dt-center',
                                                  visible=T,
                                                  targets=c("Designer",
                                                            "Games",
                                                            "Average",
                                                            "Ratings"))
                                     )
                      )
        ) %>%
        # usersrated
        formatStyle(c(
                "Ratings"),
                #     blue = 'white',
                backgroundColor = styleInterval(seq_usersrated,
                                                blueRampSeq(length(seq_usersrated)+1))) %>%
        # average
        formatStyle(c(
                "Average"),
                #     blue = 'white',
                backgroundColor = styleInterval(seq_average,
                                                colorRampDiv(length(seq_average)+1)))

```

