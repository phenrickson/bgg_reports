---
title: "Analyzing Individual BGG Users"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: TRUE #adds a Table of Contents
    theme: cerulean
    number_sections: TRUE #number your headings/sections
    toc_float: TRUE #let your ToC follow you as you scroll
    keep_md: no
    fig.caption: yes
params:
  username: "Watch%20It%20Played"
  end_training_year: 2020
  min_training_ratings: 100
---

```{r load and set packages, echo=F, warning=F, message=F,  results = 'hide'}

knitr::opts_chunk$set(echo = F,
                      error = F,
                      warning=F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

# source
source(here::here("scripts/load_packages.R"))
source(here::here("functions/theme_phil.R"))
library(patchwork)

set_flextable_defaults(theme_fun = theme_booktabs,
                       font.color = "black",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```

```{r connect to big query and query tables we need, warning=F, message=F, results='hide'}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"

# authorize
bq_auth(email = "phil.henrickson@aebs.com")

# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

# query table of game info to most recent load
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.api_game_info
                              where timestamp = (SELECT MAX(timestamp) as most_recent FROM bgg.api_game_info)') %>%
        select(-starts_with("rank")) %>%
        mutate(numweights = as.numeric(numweights)) %>%
        mutate_at(c("averageweight",
                    "playingtime",
                    "minplaytime",
                    "maxplaytime",
                    "yearpublished"),
                  ~ case_when(. == 0 ~ NA_real_,
                              TRUE ~ .))

# ugh, made a mistake in the schema...

# create caption for plots
my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))


# long table with game type variables
game_types= DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.api_game_categories')

```

```{r functions}

# source
source(here::here("functions/tidy_name_func.R"))

# get user collection
get_user_collection = function(username) {
        
        # load bgg analytics
        library(bggAnalytics)
        
        # load function for grabbing collections
        source(here::here("functions/get_collection.R"))
        
        # load collection
        get_collection(username) %>%
                        as_tibble()
        
}

# function for adding color to flextables
col_func<- function(x) {
  
  breaks<-seq(0, 1, .01)
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

```

```{r tidy the damn username}

tidy_username =  gsub("\\%20", "", params$username)

```


# What is this? {-}

This notebook contains a set of analyses for analyzing `r tidy_username` boardgamegeek collection. The bulk of the analysis is focused on building a user-specific predictive model to predict the games that the specified user is likely to own. This enables us to ask questions like, based on the games the user currently owns, what games are a good fit for their collection? What upcoming games are they likely to purchase?

```{r load previously stored data and create games model, warning=F, mesage=F, echo=F}

# laod in categorical feature selection we've made use of previously
categorical_features_selected = readr::read_rds(here::here("data",
                                                            "categorical_features_selected.Rdata"))

# select in full game types set
game_types_selected = game_types %>%
        left_join(., categorical_features_selected %>%
                          select(type, id, value, tidied, selected),
                  by = c("type", "id", "value")) %>%
        filter(selected == 'yes')

# pivot and spread these out
game_types_pivoted =game_types_selected %>%
        select(game_id, type, value) %>%
        mutate(type_abbrev = substr(type, 1, 3)) %>%
        mutate(value = tolower(gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", value))))) %>%
        mutate(type = paste(type, value, sep="_")) %>%
        mutate(has_type = 1) %>%
        select(-value) %>%
        pivot_wider(names_from = c("type"),
                            values_from = c("has_type"),
                            id_cols = c("game_id"),
                            names_sep = "_",
                            values_fn = min,
                            values_fill = 0)

# now join
games_model = active_games %>%
        left_join(.,
                  game_types_pivoted,
                  by = "game_id") %>%
        rename(numowned = owned)

rm(game_types_pivoted,
   game_types_selected)

# get most recent date
most_recent_date = as.Date(games_model$timestamp[1])

my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", most_recent_date),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))

```

```{r get user collection from bgg, warning=F, message=F, results = 'hide'}

# run function and get user collection
suppressWarnings({
suppressMessages({
        user_collection = get_user_collection(params$username)
})
})

# username
user_collection = user_collection %>%
        mutate(username = tidy_username)

```


```{r join up collection and model data} 

# deal with usernames with spaces, bleah
username = tidy_username

# combine collection data with model data
games_and_collection_data = games_model %>%
        left_join(., 
                  user_collection%>%
                          mutate(owned = case_when(own == 1 | prevowned == 1 ~ 'yes',
                                                   TRUE ~ 'no')) %>%
                          mutate(rated = case_when(!is.na(rating) ~ 'yes',
                                                  TRUE ~ 'no')) %>%
                          mutate(own = case_when(own == 1 ~ 'yes',
                                                 TRUE ~ 'no')) %>%
                          select(game_id, own, owned, rating, rated),
                  by = c("game_id")) %>%
        mutate_at(vars(own,
                       owned,
                       rated),
                  ~ replace_na(., 'no')) %>%
        mutate(username = username)

```

```{r set up training validation test split, warning=F, message=F}

# training set
games_train = games_and_collection_data %>%
        filter(yearpublished < params$end_training_year) %>%
        filter(usersrated > params$min_training_ratings)

# validation set
games_validation = games_and_collection_data %>%
        filter(yearpublished == params$end_training_year)

# test
games_test= games_and_collection_data %>%
        filter(yearpublished > params$end_training_year)

# make an initial split based on previously defined splits
validation_split = make_splits(list(analysis = seq(nrow(games_train)),
                                 assessment = nrow(games_train) + seq(nrow(games_validation))),
                               bind_rows(games_train,
                                         games_validation))

# make a second split for the training, validation, and test
test_split = make_splits(
        list(analysis = 
                     seq(nrow(games_train) + nrow(games_validation)),
             assessment = 
                     nrow(games_train) + nrow(games_validation) + seq(nrow(games_test))),
        bind_rows(games_train,
                  games_validation,
                  games_test))

```

```{r create base user recipe} 

user_recipe = recipe(games_train) %>%
        update_role(all_numeric(),
                    new_role = "predictor") %>%
        step_mutate_at(c("averageweight"),
                         fn = ~ na_if(., 0)) %>% # set to skip as this will be an outcome
        step_mutate_at(c("yearpublished",
                         "playingtime"),
                       fn = ~ na_if(., 0)) %>% # these variables come through as 0 if they are missing
        update_role(one_of("timestamp",
                           "own",
                           "owned",
                           "rated",
                           "rating",
                           "game_id",
                           "name",
                           "numcomments",
                           "numweights",
                           "numowned",
                           "trading",
                           "wanting",
                           "wishing",
                           "timestamp",
                           "average",
                           "bayesaverage",
                           "usersrated",
                           "stddev"),
                      new_role = "id") %>%
        step_filter(!is.na(yearpublished)) %>%
        step_filter(!is.na(name)) %>%
        step_mutate(missing_minage = case_when(is.na(minage) ~ 1,
                                               TRUE ~ 0)) %>%
        step_mutate(missing_playtingtime = case_when(is.na(playingtime) ~ 1,
                                                     TRUE ~ 0)) %>%
        step_impute_median(playingtime,
                           maxplayers,
                           minage) %>% # medianimpute numeric predictors
        # step_mutate(published_prior_1950 = case_when(yearpublished<1950 ~ 1,
        #                                                TRUE ~ 0)) %>%
        step_mutate(minplayers = case_when(minplayers < 1 ~ 1,
                                                     minplayers > 10 ~ 10, # truncate
                                                     TRUE ~ minplayers),
                    maxplayers = case_when(maxplayers < 1 ~ minplayers,
                                                     maxplayers > 20 ~ 20,
                                                     TRUE ~ maxplayers)) %>%
        step_rm(minplaytime, maxplaytime) %>%
        step_mutate(time_per_player = playingtime/ maxplayers) %>% # make time per player variable
        step_mutate_at(starts_with("category_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("mechanic_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("artist_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("designer_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("publisher_"),
                           fn = ~ replace_na(., 0)) %>%  
        step_mutate_at(starts_with("family_"),
                           fn = ~ replace_na(., 0)) %>%
        step_mutate(number_mechanics = rowSums(across(starts_with("mechanic_"))),
                  #    number_artists = rowSums(across(starts_with("art_"))),
                      number_categories = rowSums(across(starts_with("category_")))) %>%
        step_zv(all_predictors()) %>%
        step_nzv(all_predictors(),
                   -starts_with("publisher_"),
                   -starts_with("artist_"),
                   -starts_with("designer_"),
                   freq_cut = 100/1) %>% 
        step_corr(all_predictors(),
                  threshold = 0.9) %>%
        step_mutate(published_prior_1950 = case_when(yearpublished < 1950 ~ 1,
                                                     TRUE ~ 0)) %>%
        step_mutate(trunc_yearpublished = case_when(yearpublished < 1950 ~ 1950,
                                              TRUE ~ yearpublished)) %>% # truncate
        # step_mutate(cut_yearpublished= yearpublished) %>%
        # step_cut(cut_yearpublished,
        #                      breaks = seq(1970, 2010, 10),
        #                      include_outside_range = T) %>%
        step_mutate(cut_playingtime= playingtime) %>%
        step_cut(cut_playingtime,
                             breaks = c(15, 45, 90, 180),
                             include_outside_range = T) %>%
        step_dummy(all_nominal_predictors()) %>%
        step_log(playingtime,
                   time_per_player,
                   offset = 1) %>%
        step_dummy(all_nominal_predictors()) %>%
        step_zv(all_predictors()) %>% # remove features with no variance
        step_nzv(all_predictors(),
                   -starts_with("publisher_"),
                   -starts_with("artist_"),
                   -starts_with("designer_"),
                   freq_cut = 100/1) %>% # apply near zero variance filter
        step_nzv(starts_with("artist_"),
                 -one_of(c("artist_ian_otoole",
                           "artist_chris_quilliams")), # allow for some specific artists, well known in recent years
                 freq_cut = 250/1) %>%
        step_corr(all_predictors(),
                  threshold = 0.9) # remove highly, highly correlated features 

```

```{r now create outcome specific recipes}

# recipe for owned
recipe_owned = user_recipe %>%
        update_role(owned,
                    new_role = "outcome") %>%
        step_impute_linear(averageweight,
                     #      impute_with = imp_vars(all_predictors())) %>%
                        impute_with = imp_vars(
                                playingtime,
                                time_per_player,
                                number_mechanics)) # impute missing averageweight using simple linear model

# recipe for rated
recipe_rated = user_recipe %>%
        update_role(rated,
                    new_role = "outcome") %>%
        step_impute_linear(averageweight,
                     #      impute_with = imp_vars(all_predictors())) %>%
                        impute_with = imp_vars(
                                playingtime,
                                time_per_player,
                                number_mechanics)) # impute missing averageweight using simple linear model
```

```{r define training folds for resampling, warning=F, message=F}

# create folds for tuning
set.seed(1999)
train_folds_owned = vfold_cv(games_train,
                      strata = owned,
                      v=5)

set.seed(1999)
train_folds_rated = vfold_cv(games_train,
                      strata = rated,
                      v=5)

```


```{r define models and workflows, warning=F, message=F}

# penalized logistic regression
glmnet_class_mod<- 
        logistic_reg(penalty = tune::tune(),
                     mixture = 0.5) %>%
        set_engine("glmnet")

# specify grid for tuning
glmnet_grid <- tibble(penalty = 10^seq(-4, -0.75, 
                                       length.out = 30))

# specify regression metrics
class_metrics<-metric_set(yardstick::roc_auc,
                          yardstick::mn_log_loss)

# create workflows
# owned
owned_glmnet_workflow = 
        workflow() %>%
        add_model(glmnet_class_mod) %>%
        add_recipe(recipe_owned %>%
                           step_normalize(all_predictors()))

# rated
rated_glmnet_workflow = 
        workflow() %>%
        add_model(glmnet_class_mod) %>%
        add_recipe(recipe_owned %>%
                           step_normalize(all_predictors()))

# control for resamples
control<- control_resamples(save_pred = TRUE, 
                               save_workflow = TRUE,
                               allow_par = T)

# register parallel
library(doParallel)
numcores = parallel::detectCores()
registerDoParallel(numcores -2)

```


```{r tune models}

# tune glmnet 
# owned model
set.seed(1999)
owned_glmnet_tune = owned_glmnet_workflow %>%
        tune_grid(resamples = train_folds_owned,
                  grid = glmnet_grid,
                  control = control,
                  metrics = class_metrics)

# # tune glmnet 
# # owned model
# set.seed(1999)
# rated_glmnet_tune = rated_glmnet_workflow %>%
#         tune_grid(resamples = train_folds_rated,
#                   grid = glmnet_grid,
#                   control = control,
#                   metrics = class_metrics)

```

```{r look at our resampling results, warning=F, message=F}

# owned_glmnet_tune %>%
#         collect_metrics(summarize = F) %>%
#         ggplot(., aes(x=penalty,
#                       color = id,
#                       group = id,
#                       y = .estimate))+
#         geom_line()+
#         facet_wrap(.metric ~., scales = "free_y")+
#         theme_bw(8)+
#         scale_color_viridis_d()+
#         my_caption

## owned
# get tuning parameters
owned_glmnet_par = owned_glmnet_tune %>%
        show_best(metric = "roc_auc", n=1)

# fit on training, assess on validation
owned_glmnet_validation_last_fit = owned_glmnet_workflow %>%
        finalize_workflow(owned_glmnet_par) %>%
        last_fit(validation_split, metrics = class_metrics)

# get model fit to training set
owned_glmnet_train_fit = owned_glmnet_validation_last_fit %>%
        pluck(".workflow", 1) %>%
        extract_fit_parsnip()

# ## rated
# # get tuning parameters
# rated_glmnet_par = rated_glmnet_tune %>%
#         show_best(metric = "roc_auc", n=1)
# 
# # fit on training, assess on validation
# rated_glmnet_validation_last_fit = rated_glmnet_workflow %>%
#         finalize_workflow(rated_glmnet_par) %>%
#         last_fit(validation_split, metrics = class_metrics)
# 
# # get model fit to training set
# rated_glmnet_train_fit = rated_glmnet_validation_last_fit %>%
#         pluck(".workflow", 1) %>%
#         extract_fit_parsnip()


```


```{r get predictions from resampling, warning=F, message=F}

owned_resamples = owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        arrange(.row) %>%
        left_join(., games_train %>%
                          select(-owned) %>%
                          mutate(.row = row_number()),
                  by = c(".row")) %>%
        select(.pred_yes, .row, owned, game_id, name, yearpublished) %>%
        rename(prob = .pred_yes) %>%
        mutate_if(is.numeric, round, 3) %>%
        arrange(desc(prob)) %>%
        select(yearpublished, game_id, name, prob, owned)
        # bind_rows(.,
        #           rated_glmnet_tune %>%
        #                   collect_predictions(parameters = rated_glmnet_par) %>%
        #                   arrange(.row) %>%
        #                   left_join(., games_train %>%
        #                                     select(-rated) %>%
        #                                     mutate(.row = row_number()),
        #                             by = c(".row")) %>%
        #                   select(.pred_yes, .row, rated, game_id, name, yearpublished) %>%
        #                   rename(prob = .pred_yes) %>%
        #                   mutate_if(is.numeric, round, 3) %>%
        #                   arrange(desc(prob)) %>%
        #                   select(yearpublished, game_id, name, prob, rated)
        #           )

```

# Collection Overview

We can look at a basic description of the number of games that the user owns, has rated, has previously owned, etc.

```{r examine collection, warning=F, message=F}

# summarize
summarized = user_collection %>% 
        mutate(username = tidy_username) %>%
        left_join(., games_model, by = c("game_id")) %>%
        mutate(rated = case_when(!is.na(rating) ~ 1,
                                 TRUE ~ 0)) %>%
        mutate(owned_not_rated= case_when(rated == 0 & own == 1 ~ 1,
                                          TRUE ~ 0)) %>%
        mutate(played = case_when(own == 1 | rated == 1 | prevowned == 1 ~ 1,
                                  TRUE ~ 1)) %>%
        select(username, date, game_id, name, own, rated, prevowned, owned_not_rated, wanttoplay, fortrade, played) %>%
        group_by(username, date) %>%
        summarize(Own = sum(own),
                  `Rated, Owned, or Previously Owned` = sum(played),
                  `Previously Owned` = sum(prevowned),
                  Rated = sum(rated),
                  `For Trade` = sum(fortrade),
                  `Want To Play`= sum(wanttoplay),
                  `Own But Not Rated` = sum(owned_not_rated),
                  .groups = 'drop') %>%
        gather("variable", "value",
               -username, -date) %>%
        mutate(shame = case_when(variable == 'Own But Not Rated' ~ 'yes',
                                 TRUE ~ 'no')) %>%
        filter(variable != 'Rated, Owned, or Previously Owned') %>%
        mutate(max = max(value))

# plot
summarized %>%
        ggplot(., aes(x=reorder(variable, value),
                      label = value,
                      fill = shame,
                      y=value))+
        geom_col()+
        geom_text(hjust = -0.1)+
        theme_phil()+
        coord_flip(ylim = c(0, summarized$max[1]*1.05))+
        ylab("Number of Games")+
        xlab("")+
        ggtitle(paste(username, "'s collection on BGG", sep=""),
                subtitle = str_wrap('Games owned but not rated may potentially be a shelf of shame. In this event, these games are highlighted in red in order to potentially make the user feel bad about themselves.',100))+
        my_caption+
        scale_fill_manual(values = c("grey60", "firebrick3"))+
        guides(fill = "none")
        

```

What years has the user owned/rated games from? While we can't see when a user added or removed a game from their collection, we can look at their collection by the years in which their games were published.

```{r ownership by year, warning=F, message=F}

years = seq(1950, year(Sys.Date())+1, 1) %>%
        as_tibble() %>%
        mutate(username = username) %>%
        rename(yearpublished = value)

collection_over_time = years %>%
        left_join(., 
                user_collection %>%
                        left_join(., games_model,
                                  by = c("game_id")) %>%
                group_by(username, yearpublished) %>%
                mutate(rated = case_when(!is.na(rating) ~ 1,
                                         TRUE ~ 0)) %>%
                mutate(owned_not_rated= case_when(rated == 0 & own == 1 ~ 1,
                                                  TRUE ~ 0)) %>%
                mutate(played = case_when(own == 1 | rated == 1 | prevowned == 1 ~ 1,
                                          TRUE ~ 1)) %>%
                select(username, yearpublished, game_id, name, own, rated, prevowned, owned_not_rated, wanttoplay, fortrade, played) %>%
                group_by(username, yearpublished) %>%
                summarize(Own = sum(own),
                          `Rated, Owned, or Previously Owned` = sum(played),
                          `Previously Owned` = sum(prevowned),
                          Rated = sum(rated),
                          `For Trade` = sum(fortrade),
                          `Want To Play`= sum(wanttoplay),
                          `Own But Not Rated` = sum(owned_not_rated),
                          .groups = 'drop'),
                by = c("username", "yearpublished"))


collection_over_time %>%
        melt(id.vars = c("username", "yearpublished")) %>%
        mutate(value = replace_na(value, 0)) %>%
        filter(variable == 'Own' | variable == 'Rated') %>%
        filter(yearpublished >= 1980) %>%
        arrange(variable, yearpublished) %>%
        group_by(variable) %>%
        mutate(diff = value - dplyr::lag(value, 1)) %>%
        mutate(max_diff = max(diff, na.rm=T)) %>%
        mutate(largest_own_increase = case_when(variable == 'Own' & diff == max_diff ~ yearpublished)) %>%
  #      mutate(largest_ratings_increase = case_when(variable == 'Rated' & diff == max_diff ~ yearpublished)) %>%
        ungroup() %>%
        mutate(max = max(value, na.rm=T)) %>%
        ggplot(., aes(x=yearpublished,
                      color = variable,
                     y = value))+
        geom_vline(aes(xintercept = largest_own_increase),
                   lwd = 1.03,
                   col = 'black',
                   alpha = 0.4)+
        # geom_vline(aes(xintercept = largest_ratings_increase),
        #            lwd = 1.03,
        #            col = 'orange',
        #            alpha = 0.4)+
        geom_line(lwd=1.02)+
        # geom_col()+
        # facet_wrap(variable ~.,
        #            ncol = 1)+
       # scale_fill_colorblind()+
        scale_color_colorblind()+
        theme_phil()+
        guides(fill = "none")+
        xlab("Year Published")+
        ylab("Number of Games")+
        ggtitle(paste(username, "'s collection by Year Published", sep = ""),
                subtitle = str_wrap("Vertical bars indicate when user had largest increase in number of games owned.",100))+
        my_caption
        
```

## What types of games does `r username` own?

We can look at the most frequent types of categories, mechanics, designers, and artists that appear in a user's collection.

```{r game types, warning=F, message=F, fig.height=8, fig.width=10}

game_types %>%
        filter(game_id %in% user_collection$game_id) %>%
        filter(type %in% c("artist",
                           "category",
                           "designer",
                           "mechanic")) %>%
        mutate(username = username) %>%
        group_by(username, type, value) %>%
        summarize(n = n_distinct(game_id, na.rm=T),
                  .groups = 'drop') %>%
        group_by(type) %>%
        slice_max(order_by = n, 
                  with_ties =F,
                  n = 25) %>%
        mutate(value = tidy_name_func(value)) %>%
        # mutate(group = factor(group,
        #                       levels = c("category",
        #                                  "mechanic",
        #                                  "designer",
        #                                  "artist"))) %>%
        ggplot(., aes(x = reorder_within(value, n, within = type),
                      fill = type,
                      y = n))+
        geom_col()+
        facet_wrap(type ~.,
                   ncol = 2,
                   scales="free")+
        scale_x_reordered()+
        coord_flip()+
        theme_phil()+
        xlab("")+
        ylab("Number of Games")+
        guides(fill = "none") +
        ggtitle(paste("Top Categories, Mechanics, Designers, and Artists for ", username, sep = ""),
                subtitle = str_wrap("Filtering to top 25 most frequent features for games owned by user",90))+
        scale_fill_brewer(palette  = "Dark2")


```

# Modeling **`r tidy_username`'s** Collection

We'll examine a predictive model trained on a user's collection for games published through `r params$end_training_year`. How many games has the user owned/rated/played in the training set (games prior to `r params$end_training_year`)?

```{r get to know collection, echo=F, warning=F, message=F}

bind_rows(games_train %>%
                  mutate(dataset = "training",
                         period = paste("published before",  params$end_training_year)),
          games_validation %>%
                  mutate(dataset = "validation",
                         period = paste("published", params$end_training_year)),
          games_test %>%
                  mutate(dataset = "test",
                         period = paste("published after", params$end_training_year)
                         )) %>%
        mutate(username = tidy_username) %>%
        group_by(username, dataset, period) %>%
        mutate(owned = case_when(owned == 'yes' ~ 1,
                                 TRUE ~ 0),
               rated = case_when(rated == 'yes' ~ 1,
                                 TRUE ~ 0)) %>%
        summarize(games_owned = sum(owned),
                  games_rated = sum(rated),
                  .groups = 'drop') %>%
        mutate(dataset = factor(dataset, levels = c("training",
                                                    "validation", 
                                                    "test"))) %>%
        arrange(dataset) %>%
        flextable() %>%
        flextable::autofit()

```

<!-- There are two main (binary) outcomes we will be modeling for the user.  -->

<!-- The first, **owned** refers to whether the user currently owns or has previously owned a game in their collection. The second, **rated** refers to whether the user has rated the game. We will train predictive models to learn the probability that the user will own or play individual games based on their features.  -->

The main outcome we will be modeling for the user is **owned**, which refers to whether the user currently owns or has a previously owned a game in their collection. Our goal is to train a predictive model to learn the probability that a user will add a game to their collection based on its observable features.

## Coefficients for `r tidy_username`

We can examine coefficients from the model we trained, which is a logistic regression with elastic net regularization (which I will refer to as a penalized logistic regression).  Positive values indicate that a feature increases a user's probability of owning/rating a game, while negative values indicate a feature decreases the probability. To be precise, the coefficients indicate the effect of a particular feature on the log-odds of a user owning a game.

```{r plot coefficients, echo=F, warning=F, message=F, fig.height=11, fig.width=10}

# get coefs from model fit to trainin set
owned_glmnet_train_fit %>%
        tidy() %>%
        filter(term != '(Intercept)') %>%
        slice_max(order_by = abs(estimate),
                  n = 50,
                  with_ties = F) %>%
        arrange(desc(estimate)) %>%
        mutate(term = tidy_name_func(term)) %>%
        mutate(username = tidy_username) %>%
        ggplot(., aes(x=estimate,
                      color = estimate,
                      y=reorder(term, estimate)))+
        geom_point(size=2)+
        theme_phil()+
        geom_vline(xintercept = 0,
                   linetype = 'dashed',
                   col = 'grey60')+
        theme_phil()+
        theme(legend.title = element_text(size = 8), # remove the vertical grid lines
           panel.grid.major.x = element_blank() ,
           # explicitly set the horizontal lines (or they will disappear too)
           panel.grid.major.y = element_line( size=.1, color="grey60"))+
        xlab("Estimated Effect on Outcome")+
        ylab("")+
        my_caption+
        ggtitle(paste("What predicts ", tidy_username, "'s collection?", sep=""),
                subtitle = str_wrap(paste("Coefficients from a penalized logistic regression for games owned by specified user. Predictors centered and scaled. Model trained on games published prior to", params$end_training_year+1), 120))+
        scale_color_gradient2(low = "red",
                              mid = "grey60",
                              high = "deepskyblue2",
                              limits = c(-0.1, 0.1),
                              oob = scales::squish)+
        guides(color = guide_colorbar(barwidth = 15,
                                      barheight = 0.5,
                                      title = "Decreases Probability                               Increases Probability",
                                      title.position = 'top',
                                      label = F))

```

## Visualizing Predictors for `r tidy_username`'s Collection

Why did the model identify these features? We can make density plots of the important features for predicting whether the user owned a game. Blue indicates the density for games owned by the user, while grey indicates the density for games not owned by the user. 

```{r get top predictors for visualization, warning=F, message=F}

#  get top 16 predictors with largest absolute coefficient
top_predictors = owned_glmnet_train_fit %>%
        tidy() %>%
        mutate(abs = abs(estimate)) %>%
        filter(term != '(Intercept)') %>%
        slice_max(., order_by = abs,
            n = 16,
            with_ties = F) %>%
        pull(term)

## get just the dummy variables
dummy_predictors = owned_glmnet_train_fit %>%
        tidy() %>%
        mutate(abs = abs(estimate)) %>%
        filter(term != '(Intercept)') %>%
        filter(grepl('^family_|^mechanic_|^publisher_|^category_|^artist_', term)) %>%
        slice_max(., order_by = abs,
            n = 25,
            with_ties = F) %>%
        pull(term)

# set the levels
top_predictors_levels = tidy_name_func(top_predictors)
dummy_predictors_levels = tidy_name_func(dummy_predictors)

# numeric predictors
baked_train = recipe_owned %>%
        prep(games_train,
             strings_as_factor = F) %>%
        bake(games_train) 
  
```


```{r get top predictors, warning=F, message=F, fig.height=10, fig.width=10}

# make plot      
predictor_plot = baked_train %>%
        rename(outcome = owned) %>%
        select(username,
                 outcome,
                 game_id,
                 name,
                 yearpublished,
                 all_of(top_predictors)) %>%
        gather("variable",
               "value",
               -username, -outcome, -game_id, -name, -yearpublished) %>%
        mutate(variable = factor(tidy_name_func(variable),
                           levels = top_predictors_levels)) %>%
         ggplot(., aes(x=value,
                fill= outcome,
                color = outcome,
                y=outcome))+
         geom_density_ridges(alpha=0.6)+
         facet_wrap(variable~.,
             scales="free")+
         theme_phil()+
         scale_fill_manual(values = c("grey60", 
                               "deepskyblue1"))+
         scale_color_manual(values = c("grey60", 
                               "deepskyblue1"))+
         guides(fill = "none",
         color = "none")+
         ylab("User Owns Game?")+
         xlab("")+
         labs(title = "What Explains a User's Collection?",
                             subtitle = str_wrap(paste("Plotting density of games owned by user by top predictors from model. Data from all games published before", params$end_training_year), 90))+
         theme(panel.grid.major=element_blank(),
         panel.grid.minor = element_blank())+
         my_caption
#  mutate(variable = rename_func(variable)) %>%
  
 
suppressWarnings({
suppressMessages({
 print(predictor_plot)
})
})

```

Binary predictors can be difficult to see with this visualization, so we can also directly examine the percentage of games in a user's collection with a predictor vs the percentage of all games with that predictor.

```{r dummy predictors, warning=F, message=F}

#  , though this can also be difficult to see visually with low percentages.
diff_func <- function(x) {
  
  breaks<-seq(-0.4, 0.4, .01)
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("red", "white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
}

ratio_func <- function(x) {
  
  breaks<-seq(1, 25, .1)
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
}

ratio_func2 <- function(x) {
  
  breaks<-c(seq(0, .99, length=10),
            seq(1, 25, length = 10))
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("red", "white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
}

## get just the dummy variables
dummy_predictors2 =  owned_glmnet_train_fit %>%
        tidy() %>%
        mutate(abs = abs(estimate)) %>%
        filter(term != '(Intercept)') %>%
        filter(grepl('^family_|^mechanic_|^publisher_|^category_|^artist_', term)) %>%
        slice_max(., order_by = abs,
            n = 25,
            with_ties = F) %>%
        pull(term)

# set the levels
dummy_predictors_levels2 = tidy_name_func(dummy_predictors2)

# create table
baked_train %>%
        rename(outcome = owned) %>%
        select(username,
               outcome,
               game_id,
               name,
               yearpublished,
               all_of(dummy_predictors2)) %>%
        mutate_at(vars(dummy_predictors2),
          ~  case_when(. == 1 ~ 'yes',
                      TRUE ~ 'no')) %>%
        gather("variable",
               "value",
               -username, -outcome, -game_id, -name, -yearpublished) %>%
        mutate(variable = factor(tidy_name_func(variable),
                           levels = dummy_predictors_levels2)) %>%
        group_by(username, 
                 outcome, 
                 variable,
                 value) %>%
        summarize(n_games = n_distinct(game_id),
                  .groups = 'drop') %>%
        rename(user_owns = outcome) %>%
      #  filter(outcome == 'no') %>%
        spread(value, n_games) %>%
        arrange(variable) %>%
        mutate(prop = yes / (yes+no)) %>%
        select(username, user_owns, variable, prop) %>%
        spread(user_owns, prop) %>%
        mutate(yes = replace_na(yes, 0)) %>%
        rename(All_Games = no,
               In_Collection = yes,
               Feature = variable) %>%
        select(username, Feature, In_Collection, All_Games) %>%
     #   mutate(Difference = In_Collection - All_Games) %>%
        mutate(Ratio = (In_Collection / All_Games)) %>%
        mutate(Ratio = round(Ratio, 2)) %>%
     #          Difference_Perc = (In_Collection - All_Games) /All_Games) %>%
        arrange(desc(Ratio)) %>%
     #   mutate_if(is.numeric, round, 2) %>%
        flextable() %>%
        flextable::autofit() %>%
        bg(., j = c("All_Games",
                    "In_Collection"),
           bg = col_func) %>%
        # bg(., j = c("Difference"),
        #    bg = diff_func)  %>%
        bg(., j = c("Ratio"),
           bg = ratio_func2)  %>%
            add_header_row(values = 
                                   c(
                                           "",
                                           "",
                                           "% of Games with Feature",
                                           "% of Games with Feature",
                                      #     "",
                                           "")) %>%
    flextable::align(align = "center", part = "header") %>%
    merge_h(part = "header") %>%
    merge_v(part = "header") %>%
        set_formatter(
                In_Collection = function(x) sprintf( "%.1f%%", x*100 ),
                All_Games  = function(x) sprintf( "%.1f%%", x*100 ),
                Difference = function(x) sprintf( "%.1f%%", x*100 )
           )

        
        
        
# suppressWarnings({
# suppressMessages({
#  print(dummy_plot)
# })
# })

```

# Examine Model's Performance on Training Set

Before predicting games in upcoming years, we can examine how well the model did and what games it liked in the training set. In this case, we used resampling techniques (cross validation) to ensure that the model had not seen a game before making its predictions.

## Separation Plot

An easy way to examine the performance of classification model is to view a separation plot. We plot the predicted probabilities from the model for every game (from resampling) from lowest to highest. We then overlay a blue line for any game that the user does own. A good classifier is one that is able to *separate* the blue (games owned by the user) from the white (games not owned by the user), with most of the blue occurring at the highest probabilities (right side of the chart).

```{r separation plot for training set, echo=F, warning=F, message=F, fig.height=6, fig.width=10}

owned_resamples %>%
        mutate(username = tidy_username) %>%
        arrange(prob) %>%
        mutate(rank = row_number()) %>%
        ggplot(., aes(x=rank,
                      y=prob))+
        geom_vline(data = owned_resamples %>%
                           mutate(username = tidy_username) %>%
                           arrange(prob) %>%
                           mutate(rank = row_number()) %>%
                           filter(owned == 'yes'),
                   aes(xintercept = rank),
                  col='deepskyblue1')+
        geom_point(alpha=0.75,size=0.5)+
        facet_wrap(username~.)+
        theme_phil()+
        xlab("Game Rank (Lowest to Highest)")+
        ylab("Pr(Owned)")+
        labs(title = paste("How well did the model do?"),
             subtitle = str_wrap("Displaying cross validated probabilities for all games in the training set from least likely to most likely. Vertical blue lines indicate game was actually in the user's collection.", 125))+
        my_caption

```

## Top Games for **`r tidy_username`** from Training Set

We can display this information in table form, displaying the 100 games with the highest probability of ownership, adding a blue line when the user does own the game.

```{r top games from oos, echo=F, warning=F, message=F}

owned_resamples_table = 
owned_resamples %>%
        mutate_at(vars(c("yearpublished",
                         "game_id")),
                  ~ as.character(.)) %>%
        rename(Published = yearpublished,
               ID = game_id,
               Name = name,
               `Pr(Owned)` = prob,
               Owned = owned) %>%
        select(Published, ID, Name, `Pr(Owned)`, Owned) 

owned_resamples_table %>%
        arrange(desc(`Pr(Owned)`)) %>%
        mutate(Rank = row_number()) %>%
        select(Rank, everything()) %>%
        head(100) %>%
        flextable() %>%
        flextable::autofit() %>%
        bg(., i = ~ Owned == 'yes',
           bg = 'deepskyblue1')
```

We can also more formally assess how well the model did in resampling by looking at the area under the receiver operating characteristic. A perfect model would receive a score of 1, while a model that cannot predict the outcome will default to a score of 0.5. The extent to which something is a *good* score depends on the setting, but generally anything in the .8 to .9 range is very good while the .7 to .8 range is perfectly acceptable.

```{r assess models with roc curves, echo=F, warning=F, message=F}

# find roc_auc for resamples
owned_train_roc = owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        roc_auc(owned, .pred_yes, event_level = "second") %>%
        mutate_if(is.numeric, round, 2)  %>%
        pull(.estimate)

# pot
owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        group_by(id) %>%
        roc_curve(owned, .pred_yes, event_level = "second") %>%
        mutate(outcome = "owned") %>%
        ggplot(aes(x = 1 - specificity, 
                   group =id,
                   color = id,
                   y = sensitivity)) +
        geom_line(size = 1.02) +
        facet_wrap(outcome~.)+
        theme_phil()+
        geom_abline(lty = 2, alpha = 0.5, color = "gray50", size = 1.2)+
        scale_color_viridis_d()+
        annotate("text",
                 x = 0.12, 
                 y = .95,
                 label = paste("mean roc_auc:",
                               owned_train_roc,
                               sep = "\n"))

```

Another way to think about the model performance is to view its lift, or its ability to detect the positive outcomes over that of a null model. High lift indicates the model can much more quickly find all of the positive outcomes (in this case, games owned or played by the user), while a model with no lift is no better than random guessing. A gains chart is another way to view this.

```{r plot lift and gain curve, warning=F, message=F}

resample_lift = 
owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        lift_curve(owned, .pred_yes, event_level = "second") %>%
        mutate(outcome = "owned") %>%
        autoplot()+
        theme_phil()+
        scale_color_colorblind()+       
        ggtitle("Lift Curve")+
        facet_wrap(outcome ~.)

resample_gains = 
owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        gain_curve(owned, .pred_yes, event_level = "second") %>%
        mutate(outcome = "owned") %>%
        autoplot()+
        theme_phil()+
        scale_color_colorblind()+       
        my_caption+
        ggtitle("Gain Curve")+
        facet_wrap(outcome ~.)

resample_lift + resample_gains
```

Finally, we can understand the performance of the model by examining its calibration. If the model assigns a probability of 5%, how often does the outcome actually occur? A well calibrated model is one in which the predicted probabilities reflect the probabilities we would observe in the actual data. We can assess the calibration of a model by grouping its predictions into bins and assessing how often we observe the outcome versus how often our model expects to observe the outcome.

A model that is well calibrated will closely follow the dashed line - its expected probabilities match that of the observed probabilities. A model that consistently underestimates the probability of the event will be over this dashed line, be a while a model that overestimates the probability will be under the dashed line.

```{r assess calibration on training set, warning=F, message=F}

probs = owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        select(.pred_yes)

custom_bins = cuts <- apply(probs, 2, cut, c(0, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.25, 0.4, 0.5, 1))

owned_glmnet_tune %>%
        collect_predictions(parameters = owned_glmnet_par) %>%
        mutate(bin = cut(.pred_yes, c(0, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.25, 0.4, 0.5, 1))) %>%
   #     group_by(bin, owned) %>% count()
     #   mutate(bin = ntile(.pred_yes, 200)) %>%
   #     mutate(bin = plyr::round_any(.pred_yes, 0.05, floor)) %>%
        mutate(actual = case_when(owned == 'yes' ~ 1,
                                  TRUE ~ 0)) %>%
        group_by(bin) %>%
        summarize(n = n(),
               pred_bin = mean(.pred_yes),
               prob_bin = mean(actual),
               se = sqrt((prob_bin * (1 - prob_bin)) / n),
               ul = prob_bin + 1.96 * se, 
               ll = prob_bin - 1.96 * se) %>%
        mutate(outcome = "owned") %>%
        ggplot(.,
               aes(x = pred_bin, 
                   y = prob_bin,
                   label = n,
                   ymin = ll, 
                   ymax = ul)) +
        geom_text_repel(size=3)+
        geom_pointrange(size = 0.5, color = "black") +
         scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
         scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
        geom_abline(slope = 1,
                    intercept = 0,
                    linetype = 'dotted')+
       # geom_smooth(span = 0.9)+
        theme_phil()+
        xlab("Predicted Probability")+
        ylab("Observed Probability")+
        geom_line(alpha = 0.5)+
        my_caption+
        facet_wrap(outcome~.)+
        ggtitle("Calibration Plot")+
        annotate("text",
                 x = 0.2, 
                 y = 0.7,
                 label = "underestimates \n probability")+
        annotate("text",
                 x = 0.75, 
                 y = 0.15,
                 label = "overestimates \n probability")
        
# 
#                prob_bin = mean(as.numeric(owned)))
#         spread(owned, n) %>%
#         mutate_at(vars(yes,no),
#                   replace_na, 0) %>%
#         mutate(prop = yes / (yes+no)) %>%
#         mutate(n = no + yes) %>%
#         group_by(bin) %>%
#         mutate(bin_pred = mean(.pred_yes))
#         mutate(type = "train") %>%
#         ggplot(., aes(x=bin, 
#                       group = type,
#                       y=prop))+
#         geom_point(aes(size=n))+
#         geom_line(show.legend = F)+
#      #   scale_color_viridis_d()+
#         theme_phil()+
#         geom_abline(slope = 1,
#                     intercept = 0,
#                     linetype = 'dotted')
#         group_by
#         
#         calib


```

## Most and Least Likely Games

What games does the model think `r tidy_username` is **most likely to own** that are **not** in their collection?

```{r not in collection but likely to own, warning=F, message=F}

owned_resamples_table %>%
  filter(Owned !='yes') %>%
  slice_max(., order_by = `Pr(Owned)`, n=5, with_ties = F) %>%
  flextable() %>%
  flextable::autofit()

```

What games does the model think `r tidy_username` is **least likely to own** that **are** in their collection?

```{r in collection least likely to own, warning=F, message=F}

owned_resamples_table %>%
  filter(Owned == 'yes') %>%
  slice_min(., order_by = `Pr(Owned)`, n=5, with_ties = F) %>%
  flextable() %>%
  flextable::autofit() %>%
  bg(., i = ~ Owned == 'yes',
                   bg = 'deepskyblue1')

```

## Top Games by Year

Top 25 games most likely to be owned by the user in each year, highlighting in blue the games that the user has owned.

```{r top games from oos by year, echo=F, warning=F, message=F}

# games played
games_played = games_and_collection_data %>%
        select(yearpublished, game_id, name, owned) %>%
        gather("variable", "value",
               -yearpublished, -game_id, -name) %>%
        filter(value == 'yes') %>%
        pull(name) %>%
        unique()

# create table by year
year_table = owned_resamples %>%
        filter(yearpublished > (params$end_training_year-9)) %>%
        group_by(yearpublished) %>%
        slice_max(., order_by = prob, n=25, with_ties = F) %>%
        mutate(username = tidy_username) %>%
        select(username, yearpublished, name) %>%
        pivot_wider(., id_cols = "username",
              names_from = c("yearpublished"),
              values_from = c("name")) %>%
  unnest() %>%
  select(-username) %>%
  mutate(rank = row_number()) %>%
  select(rank, everything())

# get column names
year_names = names(year_table[,-1])

# get col funcs
bg_picker <- scales::col_factor(
    palette = "deepskyblue1",
    na.color = "white",
    ordered=F,
    levels = games_played)

# display table with colors
year_table %>%
  flextable() %>%
  flextable::autofit() %>%
  bg(., j = year_names,
     bg = bg_picker) %>%
  fontsize(size = 9, part = "all")


```

## Interactive Predictions from Resampling

Interactive table for predictions from resampling.

```{r interactie table for oos preds, warning=F, messagge=F}

owned_resamples_table %>%
        mutate(Rank = row_number()) %>%
        select(Published, ID, Name, Rank, `Pr(Owned)`, Owned) %>%
  #mutate(yearpublished = as.numeric(yearpublished)) %>%
        DT::datatable()

```

# Validating the Model on `r params$end_training_year`

We'll validate the model by looking at its predictions for games published in `r params$end_training_year`. That is, how well did a model trained on a user's collection through `r params$end_training_year` perform in predicting games for the user in `r params$end_training_year `?

```{r examine performance on validation set}

owned_assess_validation = owned_glmnet_validation_last_fit %>%
        pluck(".metrics", 1) %>%
        filter(.metric == 'roc_auc') %>%
        mutate(outcome = "owned",
               username = tidy_username,
               dataset = "validation",
               method = "glmnet") %>%
        select(username, outcome, dataset, method, .metric, .estimate) %>%
        mutate_if(is.numeric, round, 3)

# table
owned_assess_validation %>%
        flextable() %>%
        autofit()

# plot roc
p1 = owned_glmnet_validation_last_fit %>%
        pluck(".predictions", 1) %>%
        arrange(.pred_yes) %>%
        mutate(rank = row_number()) %>%
        ggplot(., aes(x= rank,
                      y = .pred_yes))+
        geom_point(size = 0.5)+
        geom_vline(data =  owned_glmnet_validation_last_fit %>%
                          pluck(".predictions", 1) %>%
                          arrange(.pred_yes) %>%
                          mutate(rank = row_number()) %>%
                          filter(owned == 'yes'),
                  aes(xintercept = rank),
                 lwd = 0.5,
                  alpha = 0.8,
                  col = 'deepskyblue1')+
        theme_phil()+
        xlab("Game Rank (Lowest to Highest)")+
        ylab("Pr(Owned)")+
        ggtitle("Separation plot")+
        theme(plot.title = element_text(size = 10))


p2 = owned_glmnet_validation_last_fit %>%
        pluck(".predictions", 1) %>%
        gain_curve(owned, .pred_yes, event_level = "second") %>%
        mutate(outcome = "owned") %>%
        autoplot()+
        theme_phil()+
        geom_abline(lty = 2, alpha = 0.5, color = "gray50", size = 1.2)+
        ggtitle("Gain curve")+
        theme(plot.title = element_text(size = 10))


# lift chart
p3 = owned_glmnet_validation_last_fit %>%
        pluck(".predictions", 1) %>%
        lift_curve(owned, .pred_yes, event_level = "second") %>%
        mutate(outcome = "owned") %>%
        autoplot()+
        theme_phil()+
        ggtitle("Lift curve")+
        theme(plot.title = element_text(size = 10))

patchwork = (p2 + p3) / p1

patchwork + plot_annotation(
  title = 'How well did model predict the validation set?',
  subtitle = str_wrap(paste("Displaying a gain curve (left) and a lift curve (right) and separation plot (bottom) to illustrate the model's performance in predicting games from", params$end_training_year), 120),
  theme = theme(plot.subtitle = element_text(size =8)))
  
```

Table of top 50 games from `r params$end_training_year`, highlighting games that the user owns.

```{r make table of validation predictions}

owned_validation_probs = owned_glmnet_validation_last_fit %>%
        pluck(".predictions", 1) %>%
        select(.pred_yes, .row, owned) %>%
        bind_cols(., games_validation %>% 
                          select(-owned)) %>% 
        select(.pred_yes, owned,name, game_id, yearpublished) %>%
        rename(prob = .pred_yes) %>%
        arrange(desc(prob)) %>%
        mutate_if(is.numeric, round, 3) %>%
        mutate_at(vars(c("yearpublished",
                         "game_id")),
                  ~ as.character(.)) %>%
        rename(Published = yearpublished,
               ID = game_id,
               Name = name,
               `Pr(Owned)` = prob,
               Owned = owned) %>%
        select(Published, ID, Name, `Pr(Owned)`, Owned) 

owned_validation_probs %>%
        head(50) %>%
        flextable() %>%
        autofit() %>%
        bg(., i = ~ Owned == 'yes',
                   bg = 'deepskyblue1')

```

# Predicting Upcoming Games (`r paste(params$end_training_year+1, " and On", sep="")`) for **`r tidy_username`**

We can then refit our model to the training and validation set in order to predict all upcoming games for the user.

```{r refit model on the trin and validation to predict the test set}

owned_glmnet_last_fit = owned_glmnet_workflow %>%
        finalize_workflow(owned_glmnet_par) %>%
        last_fit(test_split, metrics = class_metrics)

owned_upcoming_probs = owned_glmnet_last_fit %>%
        pluck(".predictions", 1) %>%
        bind_cols(., games_test %>%
                          select(-owned)) %>%
        select(.pred_yes, owned, game_id, name, yearpublished) %>%
        rename(prob = .pred_yes) %>%
        arrange(desc(prob)) %>%
                mutate_if(is.numeric, round, 3) %>%
        mutate_at(vars(c("yearpublished",
                         "game_id")),
                  ~ as.character(.)) %>%
        rename(Published = yearpublished,
               ID = game_id,
               Name = name,
               `Pr(Owned)` = prob,
               Owned = owned) %>%
        select(Published, ID, Name, `Pr(Owned)`, Owned)

```

Examine the top 50 games for upcoming games, highlighting in blue ones the user already.

```{r top games from preds, echo=F, warning=F, message=F}

owned_upcoming_probs %>%
        # left_join(., user_collection %>%
        #                   mutate(ID = as.character(game_id)) %>%
        #                   select(ID, preordered) %>%
        #                   mutate(preordered = case_when(preordered == 1 ~ 'yes',
        #                                                 TRUE ~ 'no')),
        #           by = c("ID")) %>%
        # mutate(Preordered = replace_na(preordered, "no")) %>%
        # select(-preordered) %>%
        mutate_if(is.numeric, round, 3) %>%
        head(50) %>%
        flextable() %>%
        autofit() %>%
        bg(., i = ~ Owned == 'yes',
           #| Preordered == 'yes',
                   bg = 'deepskyblue1') %>%
        set_caption(paste("Top Predicted Games for User, ", params$end_training_year+1, " and On", sep=""))

```

## Interactive Table for Validation and Upcoming Games `r paste(params$end_training_year+1, " and On", sep="")`

```{r interactive preds, echo=F, warning=F, message=F}

bind_rows(owned_upcoming_probs,
          owned_validation_probs) %>%
        arrange(desc(`Pr(Owned)`)) %>%
        mutate_if(is.numeric, round, 3) %>%
        DT::datatable()

```

```{r save workflows, warning=F, message=F, results = 'hide'}

user_owned_workflow = owned_glmnet_last_fit %>%
        pluck(".workflow", 1)

suppressMessages({
save(user_owned_workflow,
     file = here::here("user_workflows",  paste(tidy_username, "owned_workflow.Rds", sep="_")))
})

```

